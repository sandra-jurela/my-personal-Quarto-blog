{
  "hash": "6617112f7bc86ef347f30aa9130d06df",
  "result": {
    "markdown": "---\ntitle: \"Sentiment Analysis of the Dystopian Classic 'We' by Yevgeny Zamyatin\"\ndescription: \"Can negative phenomena be evoked with positive words?\"\ndate: 2023-09-10\ncategories:\n  - sentiment analysis\n  - r\nimage: img/preview.png\n---\n\n\n### Setting up the programming environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(gutenbergr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngutenberg_works(title == \"We\") %>% \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1\nColumns: 8\n$ gutenberg_id        <int> 61963\n$ title               <chr> \"We\"\n$ author              <chr> \"Zamiatin, Evgenii Ivanovich\"\n$ gutenberg_author_id <int> 51700\n$ language            <chr> \"en\"\n$ gutenberg_bookshelf <chr> NA\n$ rights              <chr> \"Public domain in the USA.\"\n$ has_text            <lgl> TRUE\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwe <- gutenberg_download(61963, strip = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwe <- read_rds(\"data/we.rds\") %>% select(-gutenberg_id)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwe\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,793 × 2\n   gutenberg_id text                                     \n          <int> <chr>                                    \n 1        61963 \"EUGENE ZAMIATIN\"                        \n 2        61963 \"\"                                       \n 3        61963 \"WE\"                                     \n 4        61963 \"\"                                       \n 5        61963 \"Authorized Translation from the Russian\"\n 6        61963 \"\"                                       \n 7        61963 \"  By\"                                   \n 8        61963 \"  GREGORY ZILBOORG\"                     \n 9        61963 \"\"                                       \n10        61963 \"  New York\"                             \n# ℹ 7,783 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add line numbers to divide text into sections\nwe %<>% \n  mutate(author = \"Yevgeny Zamyatin\",\n         title = \"We\") %>%\n  select(author, title, text) %>%        # Remove book ID number\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7,793 × 3\n   author           title text                                     \n   <chr>            <chr> <chr>                                    \n 1 Yevgeny Zamyatin We    \"EUGENE ZAMIATIN\"                        \n 2 Yevgeny Zamyatin We    \"\"                                       \n 3 Yevgeny Zamyatin We    \"WE\"                                     \n 4 Yevgeny Zamyatin We    \"\"                                       \n 5 Yevgeny Zamyatin We    \"Authorized Translation from the Russian\"\n 6 Yevgeny Zamyatin We    \"\"                                       \n 7 Yevgeny Zamyatin We    \"  By\"                                   \n 8 Yevgeny Zamyatin We    \"  GREGORY ZILBOORG\"                     \n 9 Yevgeny Zamyatin We    \"\"                                       \n10 Yevgeny Zamyatin We    \"  New York\"                             \n# ℹ 7,783 more rows\n```\n:::\n:::\n\n#### How to tidy text data\n\nThe `text` data is currently in a dataframe, but it is not **tidy** in the sense of being compatible with tidy tools. We need to transform it so that it is in a different format, with **one observation per row**.\n\nWhen we do text analysis, the observations we are interested in aren\\'t the whole talks at once, but rather individual *tokens*. A **token** is a meaningful unit of text for analysis; in many cases, this just means a single word. The process of **tokenization** identifies and breaks apart text into individual tokens. You can use [tidytext\\'s `unnest_tokens()` function](https://juliasilge.github.io/tidytext/reference/unnest_tokens.html) to accomplish all of this at once, both the tidying and the tokenization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tokenize the data\nwords_we <- we %>%\n  unnest_tokens(word, text) %>%  # Break lines into words\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 65,205 × 3\n   author           title word       \n   <chr>            <chr> <chr>      \n 1 Yevgeny Zamyatin We    eugene     \n 2 Yevgeny Zamyatin We    zamiatin   \n 3 Yevgeny Zamyatin We    we         \n 4 Yevgeny Zamyatin We    authorized \n 5 Yevgeny Zamyatin We    translation\n 6 Yevgeny Zamyatin We    from       \n 7 Yevgeny Zamyatin We    the        \n 8 Yevgeny Zamyatin We    russian    \n 9 Yevgeny Zamyatin We    by         \n10 Yevgeny Zamyatin We    gregory    \n# ℹ 65,195 more rows\n```\n:::\n:::\n\n\nWe piped in the original, non-tidy data set. We gave an argument that we want to tokenize *into* and an argument that we are tokenizing *from*.oving stop words\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwords_we %>% \n  anti_join(get_stopwords()) %>% \n  count(word, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5,695 × 2\n   word           n\n   <chr>      <int>\n 1 like         365\n 2 one          303\n 3 eyes         179\n 4 yes          151\n 5 now          136\n 6 everything   134\n 7 well         134\n 8 know         128\n 9 330          117\n10 something    117\n# ℹ 5,685 more rows\n```\n:::\n:::\n\n\nThese are now more interesting words and are starting to show the focus of the book.\n\n#### Visualize top words\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwords_we %>%\n  # remove stop words\n  anti_join(get_stopwords()) %>%\n  count(word, sort = TRUE) %>%\n  slice_max(n, n = 20) %>%\n  mutate(word = reorder(word, n)) %>%\n  # put `n` on the x-axis and `word` on the y-axis\n  ggplot(aes(x = n, y = word)) +\n  geom_col(fill = \"darkslateblue\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n### SENTIMENT FREQUENCIES\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate and print score frequencies. Sentiment scores\n# come from the AFINN lexicon, which scores the sentiment of\n# words on a scale of -5 (most negative) to +5 (most\n# positive)\nscore_freq_we <- words_we %>%\n  inner_join(get_sentiments(\"afinn\")) %>%\n  group_by(value) %>% # Grouping by sentiment scores\n  summarize(n = n()) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 2\n  value     n\n  <dbl> <int>\n1    -4    17\n2    -3   167\n3    -2   679\n4    -1   660\n5     1   754\n6     2   935\n7     3   323\n8     4    52\n9     5     1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Graph score frequencies (change scale to -5, +5)\nscore_freq_we %>% \n  ggplot(aes(value, n)) +\n  geom_bar(stat = \"identity\", fill = \"darkslateblue\") +\n  scale_x_continuous(breaks = seq(-5, 5, by = 1)) +\n  ggtitle(\"We by Zamiatin: Sentiment Scores by Words\") +\n  xlab(\"Sentiment Score\") +\n  ylab(\"Frequency of Words\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### SENTIMENT ARC\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Divide the text into sections of 100 lines and calculate a\n# sentiment score for each section\nwords_we <- words_we %>% mutate(line = row_number())\nscore_arc_we <- words_we %>% \n  inner_join(get_sentiments(\"afinn\")) %>%  # Use afinn\n  group_by(section = line %/% 100) %>%     # Divide text\n  summarize(score = mean(value)) %>%       # Section scores\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 645 × 2\n   section  score\n     <dbl>  <dbl>\n 1       0  1.75 \n 2       1  0.75 \n 3       2  0    \n 4       3  0.778\n 5       4  0.333\n 6       5  2.25 \n 7       6  0.545\n 8       7  0.4  \n 9       8  1    \n10       9 -0.286\n# ℹ 635 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot scores by section to view narrative arc\nscore_arc_we %>% \n  ggplot(aes(section, score)) +\n  geom_hline(yintercept = 0, col = \"red\") +\n  geom_line(col = \"darkslateblue\") +\n  geom_smooth(method = loess, col = \"gray40\") +  \n  ggtitle(\"We by Zamiatin: Mean Sentiment Score by Section\") +\n  ylab(\"Mean Sentiment Score\") +\n  xlab(\"Section of 100 Lines\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## ❤️ The Elementary Particles\n\n\n::: {.cell}\n\n```{.r .cell-code}\nelementary_particles <-\n  tibble(\n    author = \"Michel Houellebecq\",\n    title = \"The Elementary Particles\",\n    text = read_lines(\"data/the_elementary_particles.txt\", skip_empty_rows = TRUE)\n  )\n\nhead(elementary_particles, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n   author             title                    text                             \n   <chr>              <chr>                    <chr>                            \n 1 Michel Houellebecq The Elementary Particles \"THE ELEMENTARY PARTICLES \"      \n 2 Michel Houellebecq The Elementary Particles \"by Michel Houellebecq \"         \n 3 Michel Houellebecq The Elementary Particles \"TRANSLATED FROM THE FRENCH \"    \n 4 Michel Houellebecq The Elementary Particles \"BY FRANK WYNNE \"                \n 5 Michel Houellebecq The Elementary Particles \"Alfred A. Knopf New York 2000 \" \n 6 Michel Houellebecq The Elementary Particles \"Prologue \"                      \n 7 Michel Houellebecq The Elementary Particles \"This book is principally the st…\n 8 Michel Houellebecq The Elementary Particles \"life in Western Europe, in the …\n 9 Michel Houellebecq The Elementary Particles \"for much of his life, he was no…\n10 Michel Houellebecq The Elementary Particles \"He lived through an age that wa…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_elem_part <- elementary_particles %>% \n  mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text)\n\ntidy_elem_part\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 87,196 × 4\n   author             title                    linenumber word       \n   <chr>              <chr>                         <int> <chr>      \n 1 Michel Houellebecq The Elementary Particles          1 the        \n 2 Michel Houellebecq The Elementary Particles          1 elementary \n 3 Michel Houellebecq The Elementary Particles          1 particles  \n 4 Michel Houellebecq The Elementary Particles          2 by         \n 5 Michel Houellebecq The Elementary Particles          2 michel     \n 6 Michel Houellebecq The Elementary Particles          2 houellebecq\n 7 Michel Houellebecq The Elementary Particles          3 translated \n 8 Michel Houellebecq The Elementary Particles          3 from       \n 9 Michel Houellebecq The Elementary Particles          3 the        \n10 Michel Houellebecq The Elementary Particles          3 french     \n# ℹ 87,186 more rows\n```\n:::\n:::\n\n\n### Most common positive and negative words\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_elem_part %>% \n  inner_join(get_sentiments(\"bing\")) %>% \n  count(word, sentiment) %>% \n  group_by(sentiment) %>%\n  slice_max(n, n = 10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(n, word, fill = sentiment)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(~ sentiment, scales = \"free\") +\n    theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_elem_part %>%\n  inner_join(get_sentiments(\"afinn\")) %>%\n  group_by(value) %>% # Grouping by sentiment scores\n  summarize(n = n()) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   value     n\n   <dbl> <int>\n 1    -5    63\n 2    -4   108\n 3    -3   384\n 4    -2   904\n 5    -1   788\n 6     1   786\n 7     2  1001\n 8     3   580\n 9     4    33\n10     5     1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_elem_part %>%\n  inner_join(get_sentiments(\"afinn\")) %>%\n  group_by(value) %>% # Grouping by sentiment scores\n  summarize(n = n()) %>% \n  ggplot(aes(value, n)) +\n  geom_bar(stat = \"identity\", fill = \"lightblue\", color = \"black\") +\n  scale_x_continuous(breaks = seq(-5, 5, by = 1)) +\n  ggtitle(\"The Elementary Particles Sentiment Scores by Words\") +\n  xlab(\"Sentiment Score\") +\n  ylab(\"Frequency of Words\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_elem_part %>% \n  inner_join(get_sentiments(\"afinn\")) %>%  # Use afinn\n  group_by(section = linenumber %/% 100) %>%     # Divide text\n  summarize(score = mean(value)) %>%     # Section scores\n  ggplot(aes(section, score)) +\n  geom_hline(yintercept = 0, col = \"red\") +\n  geom_line(col = \"darkslateblue\") +\n  geom_smooth(method = loess, col = \"gray40\") +  \n  ggtitle(\"The Elementary Particles: Mean Sentiment Score by Section\") +\n  ylab(\"Mean Sentiment Score\") +\n  xlab(\"Section of 100 Lines\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n## ❤️ The Genius and the Goddess\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenius <-\n  tibble(\n    author = \"Aldous Huxley\",\n    title = \"The Genius and the Goddess\",\n    text = read_lines(\"data/the_genius_and_the_goddess.txt\", skip_empty_rows = TRUE)\n  )\n\nhead(genius, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n   author        title                      text                                \n   <chr>         <chr>                      <chr>                               \n 1 Aldous Huxley The Genius and the Goddess \"                             ALDOU…\n 2 Aldous Huxley The Genius and the Goddess \"                             The G…\n 3 Aldous Huxley The Genius and the Goddess \"                              the …\n 4 Aldous Huxley The Genius and the Goddess \"                     Copyright © A…\n 5 Aldous Huxley The Genius and the Goddess \"“The trouble with fiction,” said J…\n 6 Aldous Huxley The Genius and the Goddess \"sense. Reality never makes sense.”\"\n 7 Aldous Huxley The Genius and the Goddess \"“Never?” I questioned.\"            \n 8 Aldous Huxley The Genius and the Goddess \"“Maybe from God’s point of view,” …\n 9 Aldous Huxley The Genius and the Goddess \"has unity, fiction has style. Fact…\n10 Aldous Huxley The Genius and the Goddess \"existence is always one damned thi…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_genius <- genius %>% \n  mutate(linenumber = row_number()) %>%\n  unnest_tokens(word, text)\n\ntidy_genius\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 32,800 × 4\n   author        title                      linenumber word     \n   <chr>         <chr>                           <int> <chr>    \n 1 Aldous Huxley The Genius and the Goddess          1 aldous   \n 2 Aldous Huxley The Genius and the Goddess          1 huxley   \n 3 Aldous Huxley The Genius and the Goddess          2 the      \n 4 Aldous Huxley The Genius and the Goddess          2 genius   \n 5 Aldous Huxley The Genius and the Goddess          2 and      \n 6 Aldous Huxley The Genius and the Goddess          3 the      \n 7 Aldous Huxley The Genius and the Goddess          3 goddess  \n 8 Aldous Huxley The Genius and the Goddess          4 copyright\n 9 Aldous Huxley The Genius and the Goddess          4 aldous   \n10 Aldous Huxley The Genius and the Goddess          4 huxley   \n# ℹ 32,790 more rows\n```\n:::\n:::\n\n\n### Most common positive and negative words\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_genius %>% \n  inner_join(get_sentiments(\"bing\")) %>% \n  count(word, sentiment) %>% \n  group_by(sentiment) %>%\n  slice_max(n, n = 10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(n, word, fill = sentiment)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(~ sentiment, scales = \"free\") +\n    theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_genius %>%\n  inner_join(get_sentiments(\"afinn\")) %>%\n  group_by(value) %>% # Grouping by sentiment scores\n  summarize(n = n()) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 2\n  value     n\n  <dbl> <int>\n1    -5     1\n2    -4    22\n3    -3   256\n4    -2   462\n5    -1   289\n6     1   314\n7     2   422\n8     3   288\n9     4    67\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_genius %>%\n  inner_join(get_sentiments(\"afinn\")) %>%\n  group_by(value) %>% # Grouping by sentiment scores\n  summarize(n = n()) %>% \n  ggplot(aes(value, n)) +\n  geom_bar(stat = \"identity\", fill = \"seagreen3\", color = \"black\") +\n  scale_x_continuous(breaks = seq(-5, 5, by = 1)) +\n  ggtitle(\"The Genius and the Goddess Sentiment Scores by Words\") +\n  xlab(\"Sentiment Score\") +\n  ylab(\"Frequency of Words\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_genius %>% \n  inner_join(get_sentiments(\"afinn\")) %>%  # Use afinn\n  group_by(section = linenumber %/% 25) %>%     # Divide text\n  summarize(score = mean(value)) %>%     # Section scores\n  ggplot(aes(section, score)) +\n  geom_hline(yintercept = 0, col = \"red\") +\n  geom_line(col = \"darkslateblue\") +\n  geom_smooth(method = loess, col = \"gray40\") +  \n  ggtitle(\"The Genius and the Goddess: Mean Sentiment Score by Section\") +\n  ylab(\"Mean Sentiment Score\") +\n  xlab(\"Section of 100 Lines\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntxtclean <- function(x, title){\n  require(dplyr)\n  require(stringr)\n  require(tibble)\n  x <- x %>%\n    select(text) %>% \n    iconv(to = \"UTF-8\") %>%\n    base::tolower() %>%\n    paste0(collapse = \" \") %>%\n    stringr::str_squish()%>%\n    stringr::str_split(\" \") %>%\n    unlist() %>%\n    tibble::tibble() %>%\n    dplyr::select(word = 1, everything()) %>%\n    dplyr::mutate(novel = title) %>%\n    dplyr::anti_join(stop_words) %>%\n    dplyr::mutate(word = str_remove_all(word, \"\\\\W\")) %>%\n    dplyr::filter(word != \"\")\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwe <- txtclean(we, \"We\")\nelementary_particles <- txtclean(elementary_particles, \"The Elementary Particles\")\ngenius <- txtclean(genius, \"The Genius and the Goddess\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnovels <- bind_rows(we, elementary_particles, genius)\n\nnovels %>% \n  count(novel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  novel                          n\n  <chr>                      <int>\n1 The Elementary Particles   40028\n2 The Genius and the Goddess 16308\n3 We                         31713\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(novels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 88,049\nColumns: 2\n$ word  <chr> \"ceugene\", \"zamiatin\", \"we\", \"authorized\", \"translation\", \"russi…\n$ novel <chr> \"We\", \"We\", \"We\", \"We\", \"We\", \"We\", \"We\", \"We\", \"We\", \"We\", \"We\"…\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnovels_anno <- novels %>% \n  group_by(novel) %>%\n  mutate(words = n()) %>%\n  left_join(get_sentiments(\"nrc\")) %>%\n  mutate(novel = factor(novel),\n         sentiment = factor(sentiment))\n\nnovels_anno\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 109,113 × 4\n# Groups:   novel [3]\n   word        novel words sentiment\n   <chr>       <fct> <int> <fct>    \n 1 ceugene     We    31713 <NA>     \n 2 zamiatin    We    31713 <NA>     \n 3 we          We    31713 <NA>     \n 4 authorized  We    31713 positive \n 5 translation We    31713 trust    \n 6 russian     We    31713 <NA>     \n 7 by          We    31713 <NA>     \n 8 gregory     We    31713 <NA>     \n 9 zilboorg    We    31713 <NA>     \n10 york        We    31713 <NA>     \n# ℹ 109,103 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnovels_ <- novels_anno %>%\n  group_by(novel) %>%\n  group_by(novel, sentiment) %>%\n  summarise(sentiment = unique(sentiment),\n                   sentiment_freq = n(),\n                   words = unique(words)) %>%\n  filter(is.na(sentiment) == F) %>%\n  mutate(percentage = round(sentiment_freq/words*100, 1))\n\nnovels_\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 × 5\n# Groups:   novel [3]\n   novel                    sentiment    sentiment_freq words percentage\n   <fct>                    <fct>                 <int> <int>      <dbl>\n 1 The Elementary Particles anger                  1015 40028        2.5\n 2 The Elementary Particles anticipation           1747 40028        4.4\n 3 The Elementary Particles disgust                 900 40028        2.2\n 4 The Elementary Particles fear                   1402 40028        3.5\n 5 The Elementary Particles joy                    1590 40028        4  \n 6 The Elementary Particles negative               2688 40028        6.7\n 7 The Elementary Particles positive               3832 40028        9.6\n 8 The Elementary Particles sadness                1494 40028        3.7\n 9 The Elementary Particles surprise                823 40028        2.1\n10 The Elementary Particles trust                  2200 40028        5.5\n# ℹ 20 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnovels_ %>%\n  filter(sentiment != \"positive\",\n         sentiment != \"negative\") %>%\n  ggplot(aes(sentiment, percentage, fill = novel)) +    \n  geom_bar(stat=\"identity\",   \n           position=position_dodge()) + \n  scale_fill_manual(name = \"\", values=c(\"orange\", \"gray70\", \"red\")) +\n  theme_bw() +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnovels_ %>%\n  filter(sentiment != \"positive\",\n         sentiment != \"negative\") %>%\n  mutate(sentiment = factor(sentiment, \n                            levels = c(\"anger\", \"fear\", \"disgust\", \"sadness\",\n                                   \"surprise\", \"anticipation\", \"trust\", \"joy\"))) %>%\n  ggplot(aes(novel, percentage, fill = sentiment)) +    \n  geom_bar(stat=\"identity\", position=position_dodge()) + \n  scale_fill_brewer(palette = \"RdBu\") +\n  theme_bw() +\n  theme(legend.position = \"right\") +\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](we_yevgeny_zamyatin_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "we_yevgeny_zamyatin_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}