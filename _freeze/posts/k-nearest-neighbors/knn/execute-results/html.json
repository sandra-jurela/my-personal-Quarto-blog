{
  "hash": "b0034c67c7934deae6f54ac536e3abfa",
  "result": {
    "markdown": "---\ntitle: K Nearest Neighbors\ndescription: 'Machine Learning with Python: K Nearest Neighbors.'\ndate: '2023-03-10'\ncategories:\n  - knn\n  - python\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Import required libraries\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Load iris dataset\niris = load_iris()\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Split features and target variable\nX = iris.data[:, :2] # only first two features for visualization\ny = iris.target\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Create a KNN classifier with k=3 neighbors\nknn = KNeighborsClassifier(n_neighbors=3)\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Train the model on the data\nknn.fit(X, y)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nKNeighborsClassifier(n_neighbors=3)\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Visualize decision boundaries of trained classifier\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(10,7))\nplt.contourf(xx, yy, Z)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<matplotlib.contour.QuadContourSet at 0x16087d2c130>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](knn_files/figure-html/cell-7-output-2.png){width=794 height=549}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Plot the training points onto the figure with different colors for each class label.\nscatter_x = X[:,0]\nscatter_y = X[:,1]\ngroup = y.tolist()\ncdict ={0:'purple',1:'lightgreen',2:'orange'}\nfor g in np.unique(group):\n    ix=np.where(group==g)\n    plt.scatter(scatter_x[ix], scatter_y[ix], c=cdict[g], label=g,s=100)\n\nplt.xlabel('Sepal Length')\nplt.ylabel('Sepal Width')\nplt.title('KNN Decision Boundaries')\nplt.legend(title='Classes')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](knn_files/figure-html/cell-8-output-1.png){width=589 height=442}\n:::\n:::\n\n\n",
    "supporting": [
      "knn_files"
    ],
    "filters": [],
    "includes": {}
  }
}