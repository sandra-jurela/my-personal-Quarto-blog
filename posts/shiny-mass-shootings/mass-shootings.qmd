---
title: "Shiny App - Mass Shootings in the USA"
description: "EDA with Shiny app on mass shootings between August 20th, 1982 and March 27th, 2023."
date: "2023-03-01"
categories: 
  - R
  - shiny
  - EDA
  - data cleaning
image: images/preview.png
---

::: {.callout-note appearance="simple"}
This post will be regularly updated with each new case.

Last update on March 29, 2023.
:::

<br/>

## Introduction

Mass shootings have been a topic of intense discussion in the United States. A public "database" of mass shootings since 1982 has been made available by the [Mother Jones](https://www.motherjones.com/politics/2012/12/mass-shootings-mother-jones-full-data/), a non-profit organization. This "database" is stored in a Google spreadsheet. You can view it [here](https://docs.google.com/spreadsheets/d/1b9o6uDO18sLxBqPwl_Gh9bnhW-ev_dABH83M5Vb5L8o/edit#gid=0) and download as a CSV file.

There are many definitions of mass shooting. Here is what [Britannica](https://www.britannica.com/topic/mass-shooting) has to say:

> ***Mass shooting**, also called **active shooter incident**, as defined by the U.S. [Federal Bureau of Investigation](https://www.britannica.com/topic/Federal-Bureau-of-Investigation) (FBI), an event in which one or more individuals are "actively engaged in killing or attempting to kill people in a populated area. Implicit in this definition is the shooter's use of a firearm." The FBI has not set a minimum number of casualties to qualify an event as a mass shooting, but U.S. statute (the Investigative Assistance for Violent Crimes Act of 2012) defines a "mass killing" as **"3 or more killings in a single incident".***

## Data overview

```{r}
library(tidyverse)
library(tidygeocoder)
library(plotly)
theme_set(theme_classic())

mass_shootings <- read_csv("data/mass_shootings_usa_1982-2023.csv")

mass_shootings %>% glimpse()
```

We have 141 cases, described with 24 variables. At first glance, this dataset clearly needs extensive cleaning.

## Data cleaning

### üßπ Step 1. Initial cleaning

The first cleaning step includes:

-   selecting columns of interest,
-   replacing the character value`"-"` with `NA` in all columns with character data type,
-   converting `date` column from character to date data type,
-   renaming location columns,
-   converting character data type to numeric for specific columns.

```{r}
mass_shootings_cln <- mass_shootings %>% 
  select(1:6, 8:10, 12, 16, 17, 21:24) %>% 
  mutate(across(where(is.character), ~na_if(., "-"))) %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  rename(location = location...2, location_2 = location...8) %>% 
  mutate_at(c("injured", "age_of_shooter", "latitude", "longitude"), as.numeric)
  
mass_shootings_cln %>% glimpse()
```

üîé Are there any duplicates? No.

```{r}
sum(duplicated(mass_shootings))
```

üîé Number of missing values, `NA`, per column.

```{r}
mass_shootings_cln %>% 
  summarise_all(~sum(is.na(.))) %>% 
  # transposing for better visibility
  pivot_longer(cols = everything(), names_to = "column", values_to = "n_missing")
```

15 of the most recent cases don't have location coordinates at all. We'll address this in the final cleanup step.

### üßπ Step 2. Fixing unique values of categorical variables

üîé Let's take a look at the unique values of the `gender` column.

```{r}
mass_shootings_cln %>% 
  count(gender, sort = TRUE) 
```

Almost all categorical variables need unique values correction.

To make a long story short, I'll correct them all in one step using `case_when` function, and we'll look at them later during the analysis.

```{r}
mass_shootings_cln <- mass_shootings_cln %>% 
  mutate(gender = case_when(gender == "F" ~ "Female",
                            gender == "M" ~ "Male", 
                            gender %>% str_detect("transgender")~"Female (transgender)",
                            TRUE ~ gender),
         race = case_when(race == "white" ~ "White",
                          race == "black" ~ "Black",
                          race == "unclear" ~ "Unclear",
                          TRUE ~ race),
         location_2 = 
           case_when(location_2 %in% c("workplace", "\nWorkplace") ~ "Workplace",
                                location_2 == "Other\n" ~ "Other",
                                location_2 == "religious" ~ "Religious",
                                TRUE ~ location_2),
         prior_signs_mental_health_issues = 
           case_when(prior_signs_mental_health_issues == "yes" ~ "Yes",
                     prior_signs_mental_health_issues == "TBD" ~ "To be determined",
                     TRUE ~ prior_signs_mental_health_issues),
         weapons_obtained_legally = 
           case_when(weapons_obtained_legally %in% c("yes", "\nYes") ~ "Yes",
                     weapons_obtained_legally == "TBD" ~ "To be determined",
                     weapons_obtained_legally %>% str_detect("Kelley") ~ "Unknown",
                     weapons_obtained_legally %>% str_detect("some") ~ "Partially",
                     TRUE ~ weapons_obtained_legally))
```

### üßπ Step 3. Geocoding locations with missing coordinates

There are 15 cases with missing location coordinates. In this step we'll convert locations to coordinates with geocoding. and use them later to create a `leaflet` map for a `shiny app`.

The `tidygeocoder` package provides geocoding services. It's designed to work easily with the `tidyverse.` It also provides access to several different geocoding services, including [LocationIQ](https://locationiq.com/) which I'm going to use here. LocationIQ is a freemium service that provides a free tier, which doesn't require you to give them your billing details. When you sign up to LocationIQ, they'll take you to the Manage Your API Access Tokens page, which is where we obtain our API token. Next, you need to provide the `tidygeocoder` package with your API key.

You can also use the [Nominatim ("osm")](https://nominatim.org/) geocoding service (OpenStreetMap) which can be specified with the method argument (`method = "osm"`). I found LocationIQ to be faster.

The first step is to select only locations with missing coordinates and geocode them.

```{r}
geocoded_locations <- mass_shootings_cln %>% 
  filter(is.na(latitude) | is.na(longitude)) %>% 
  select(location) %>% 
  geocode(location, method = "iq")

geocoded_locations %>% 
  mutate(across(where(is.numeric), ~ num(., digits = 6)))
```

The next step is to join mass shootings table with geocoded locations and replace missing latitudes and longitudes with geocoded.

```{r}
mass_shootings_cln <- mass_shootings_cln %>% 
  left_join(geocoded_locations, by = "location") %>% 
  mutate(latitude = ifelse(is.na(latitude), lat, latitude),
         longitude = ifelse(is.na(longitude), long, longitude))
```

üîé Checking for null values.

```{r}
sum(is.na(mass_shootings_cln$latitude))
sum(is.na(mass_shootings_cln$longitude))
```

OK, this looks fine.

## Exploratory data analysis (EDA)

### ‚ùï Writing a function

To count unique values for all categorical variables separately, I'll write a function, `count_unique`, to avoid copying and pasting a block of code several times.

This is the case when have the data-variable (column name) in a function argument. We need to embrace the argument by surrounding it in doubled braces, like `group_by({{ var }})`.

```{r}
count_unique <- function(data, var) {
  
  data %>%
    group_by({{ var }}) %>%    
    summarise(count = n(), .groups = "drop") %>% 
    mutate(percent = scales::percent(count/sum(count), accuracy = 0.1)) %>% 
    arrange(desc(count))

}
```

### üìÑ Breakdown by categorical variables

#### Gender

```{r}
mass_shootings_cln %>% count_unique(gender)
```

#### Race

```{r}
mass_shootings_cln %>% count_unique(race)
```

#### Specific location

```{r}
mass_shootings_cln %>% count_unique(location_2)
```

#### Prior signs of mental health issues

```{r}
mass_shootings_cln %>% count_unique(prior_signs_mental_health_issues)
```

#### Weapons obtained legally

```{r}
mass_shootings_cln %>% count_unique(weapons_obtained_legally)
```

#### Type

```{r}
mass_shootings_cln %>% count_unique(type)
```

Note: Spree shootings here have three or more victims in a short time in multiple locations.

### üìä Age of shooter distribution

```{r}
#| code-fold: true
# create age group column
mass_shootings_cln <-  mass_shootings_cln %>% 
  mutate(age_group = case_when(
    age_of_shooter >= 10 & age_of_shooter <= 14 ~ "10-15",
    age_of_shooter <= 19 ~ "15-20",
    age_of_shooter <= 24 ~ "20-25",
    age_of_shooter <= 29 ~ "25-30",
    age_of_shooter <= 34 ~ "30-35",
    age_of_shooter <= 39 ~ "35-40",
    age_of_shooter <= 44 ~ "40-45",
    age_of_shooter <= 49 ~ "45-50",
    age_of_shooter <= 54 ~ "50-55",
    age_of_shooter <= 59 ~ "55-60",
    age_of_shooter <= 64 ~ "60-65",
    age_of_shooter <= 69 ~ "65-70",
    age_of_shooter <= 74 ~ "70-75"))
```

```{r}
p1 <- mass_shootings_cln %>% 
  filter(!is.na(age_group)) %>% 
  group_by(age_group) %>% 
  summarise(count = n(), .groups = "drop") %>% 
  mutate(percent = scales::percent(count/sum(count), accuracy = 0.1)) %>% 
  mutate(label_text = str_glue("Age group: {age_group}
                               Count: {count}
                               Percent: {percent}")) %>%
  ggplot(aes(x = age_group, y = count, text = label_text)) +
  geom_col(width = 0.7, fill = "indianred") +
  labs(title = "Age Distribution", x = "age group") 

ggplotly(p1, tooltip = "text")
           
```

<br/>

-   The vast majority of shooters were between 15 and 50 years old.
-   Most shooters were in the 20-25 age group (18.7 %), followed by 40-45 (16.5 %) and 25-30 (15.8 %).

üîé Who was the youngest shooter?

```{r}
index <- which.min(mass_shootings_cln$age_of_shooter)

mass_shootings_cln[index, ] %>% 
  select(case, date, summary, fatalities) %>% 
  knitr::kable()
```

### üìä Number of cases per year

```{r}
p2 <- mass_shootings_cln %>%
  group_by(year) %>%
  summarise(count = n()) %>% 
  ggplot(aes(year, count)) +
  geom_col(fill = "steelblue") + 
  geom_smooth(method = "loess", se = FALSE, color = "indianred", size = 0.7) +
  # geom_vline(xintercept = 2012, color = "black", linetype = "dotted") +
  labs(title = "Number of Cases per Year") 

ggplotly(p2)
```

<br>

-   We can see an increase in mass shootings in the last 12 years.
-   2020 has a smaller number of cases probably due to Covid restrictions.
-   The data for 2023 is incomplete, but 4 cases in the first three months seems a lot.

### üìä Fatalities-Injured relationship

```{r}
p3 <- mass_shootings_cln %>%
  ggplot(aes(x = fatalities, y = injured)) +
  geom_jitter() +
  scale_y_sqrt() +
  labs(title = "Fatalities-Injured Relationship")
  
ggplotly(p3)
```

<br>

Please note that the `Injured` values are square root scaled for better visibility, but you can see the actual values by hovering over the points.

**Summary of fatalities**

```{r}
summary(mass_shootings_cln$fatalities)
```

**Summary of injured people**

```{r}
summary(mass_shootings_cln$injured)
```

### üìä Total fatalities by state

#### üõ†Ô∏è Data manipulation

```{r}
# create us states with abbreviations tibble
states_with_abbr <- 
  tibble(state = state.name, abbr = state.abb) %>% 
  bind_rows(tibble(state = "District of Columbia", abbr = "DC"))

# data manipulation
by_state <- mass_shootings_cln %>% 
  # recode some location values
  mutate(location = case_when(
    location == "Nashville, TN" ~ "Nashville, Tennessee",
    location == "Washington, D.C." ~ "Washington, District of Columbia", 
    TRUE ~ location)) %>% 
  # separate location into city and state
  separate(location, c("city", "state"), sep = ", ") %>% 
  # group and summarize
  group_by(state) %>% 
  summarise(total_cases = n(),
            total_fatalities = sum(fatalities), .groups = "drop") %>% 
  # add us states abbreviations
  left_join(states_with_abbr, by = "state") %>% 
  # rearrange columns
  select(state, abbr, everything())
```

#### üìà Top ten states regarding number of cases and fatalities

```{r}
by_state %>% 
  arrange(-total_cases, -total_fatalities) %>% 
  head(10)
```

#### üìä Total fatalities by state visualization

```{r}
by_state %>% 
  plot_geo(locationmode = 'USA-states') %>% 
  add_trace(z = ~total_fatalities,
            locations = ~abbr,
            color = ~total_fatalities,
            colors = ~"Reds") %>% 
  layout(
    geo = list(
      scope = "usa",
      projection = list(type = "albers usa"),
      lakecolor = toRGB("white")
    )
  )
```


```{r}
#| include: false
# write csv file for shiny app
mass_shootings_shiny <- mass_shootings_cln %>% 
  select(location, date, year, latitude, longitude, fatalities, summary) %>% 
  write_csv("data/mass_shootings_shiny.csv")
  
```

## Shiny app

The app you can see below is embedded in this `quarto` document since my website is static. It was originally published on [shinyapps.io](https://www.shinyapps.io/) and you can also interact with it [here](https://sandra-jurela.shinyapps.io/shiny-mass-shootings-usa/).

**A quick note:** With a free account I have 25 active hours (when my applications are not idle). If these 25 active hours are exceeded, my app will not be available again until the following month cycle. Hope you get lucky! üòä

üì¢ By clicking on each circle, you can read a summary of the mass shooting case.

<br>

::: column-page
<iframe height="800" width="100%" frameborder="no" src="https://sandra-jurela.shinyapps.io/shiny-mass-shootings-usa/">

</iframe>
:::
