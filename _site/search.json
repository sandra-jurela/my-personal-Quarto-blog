[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Let’s be friends",
    "section": "",
    "text": "Hi and welcome to my personal blog. My name is Sandra Jurela and here I will be sharing my journey into Data Science. Recently I have developed a real passion for Data Science and this blog truly is a manifestation of that.\nI hold a Master’s degree in Civil Engineering (Hydrology and Water Resources Science). I started my career as a construction designer, and then for 10 years worked as a hydrologist at the Croatian Meteorological and Hydrological Service. I currently work for my family’s business.\nI live in Zagreb, Croatia, with my two boys (life partner and our sweet son).\nIf you’d like to connect with me, please do. I hope you enjoy your visit!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sandra Jurela",
    "section": "",
    "text": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes\n\n\n\n\n\n\n\nweb scraping\n\n\ndata wrangling\n\n\nrvest\n\n\nR\n\n\nTableau\n\n\n\n\nScraping data on movies from Rotten Tomatoes and finally creating a dashboard in Tableau\n\n\n\n\n\n\nSep 1, 2022\n\n\nSandra Jurela\n\n\n\n\n\n\n  \n\n\n\n\nTitanic Survival Exercises\n\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\ndata visualization\n\n\n\n\nAssessment of visualization skills acquired in the HarvardX’s Data Science: Visualization course.\n\n\n\n\n\n\nJun 9, 2022\n\n\nSandra Jurela\n\n\n\n\n\n\n  \n\n\n\n\nCustomer Analysis – Advanced Plots With {ggplot2}\n\n\n\n\n\n\n\ndata wrangling\n\n\ndata visualization\n\n\nSQL\n\n\nPostgreSQL\n\n\nR\n\n\n\n\nQuerying database in R code chunk and making some useful plots with ggplot2.\n\n\n\n\n\n\nMay 20, 2022\n\n\nSandra Jurela\n\n\n\n\n\n\n  \n\n\n\n\nAnswering Business Questions Using SQL\n\n\n\n\n\n\n\nSQL\n\n\nSQLite\n\n\nDataquest\n\n\ndata visualization\n\n\nR\n\n\n\n\nMy SQL project for the “Intermediate SQL for Data Analysis” course at Dataquest.\n\n\n\n\n\n\nFeb 15, 2022\n\n\nSandra Jurela\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html",
    "href": "posts/answering-business-questions-using-sql/chinook.html",
    "title": "Answering Business Questions Using SQL",
    "section": "",
    "text": "The aim of this project is to explore a modified version of the Chinook database using SQL and answer some business questions. The Chinook database represents a fictional digital media shop, based on real data from an iTunes Library and manually generated data. The database is provided as a SQLite database file called chinook.db.\nHere’s a schema diagram for the Chinook database:"
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#connecting-to-the-database-and-data-overview",
    "href": "posts/answering-business-questions-using-sql/chinook.html#connecting-to-the-database-and-data-overview",
    "title": "Answering Business Questions Using SQL",
    "section": "Connecting to the Database and Data Overview",
    "text": "Connecting to the Database and Data Overview\n\nlibrary(DBI)\n\ndb <- dbConnect(RSQLite::SQLite(), dbname = \"data/chinook.db\")\n\nListing all tables in the Chinook database.\n\nSELECT\n  name,\n  type\nFROM sqlite_master\nWHERE type IN (\"table\", \"view\")\n\n\n11 records\n\n\nname\ntype\n\n\n\n\nalbum\ntable\n\n\nartist\ntable\n\n\ncustomer\ntable\n\n\nemployee\ntable\n\n\ngenre\ntable\n\n\ninvoice\ntable\n\n\ninvoice_line\ntable\n\n\nmedia_type\ntable\n\n\nplaylist\ntable\n\n\nplaylist_track\ntable\n\n\ntrack\ntable\n\n\n\n\n\nThe database consists of 11 tables containing information about artists, albums, media tracks, playlists, invoices, customers, and shop employees. Let’s start by getting familiar with our data from the main tables:\nemployee table\n\nSELECT *\nFROM employee\nLIMIT 5\n\n\n\n\n\n  \n\n\n\ncustomer table\n\nSELECT *\nFROM customer\nLIMIT 5\n\n\n\n\n\n  \n\n\n\ninvoice table\n\nSELECT *\nFROM invoice\nLIMIT 5\n\n\n\n\n\n  \n\n\n\ninvoice_line table\n\nSELECT *\nFROM invoice_line\nLIMIT 30\n\n\n\n\n\n  \n\n\n\ntrack table\n\nSELECT *\nFROM track\nLIMIT 20"
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#selecting-albums-to-purchase",
    "href": "posts/answering-business-questions-using-sql/chinook.html#selecting-albums-to-purchase",
    "title": "Answering Business Questions Using SQL",
    "section": "1. Selecting Albums to Purchase",
    "text": "1. Selecting Albums to Purchase\nThe Chinook record store has just signed a deal with a new record label, and you’ve been tasked with selecting the first three albums that will be added to the store, from a list of four. All four albums are by artists that don’t have any tracks in the store right now - we have the artist names, and the genre of music they produce:\n\n\n\nArtist Name\nGenre\n\n\n\n\nRegal\nHip-Hop\n\n\nRed Tone\nPunk\n\n\nMeteor and the Girls\nPop\n\n\nSlim Jim Bites\nBlues\n\n\n\nThe record label specializes in artists from the USA, and they have given Chinook some money to advertise the new albums in the USA, so we’re interested in finding out which genres sell the best in the USA.\nYou’ll need to write a query to find out which genres sell the most tracks in the USA, write up a summary of your findings, and make a recommendation for the three artists whose albums we should purchase for the store.\nInstructions\n\nWrite a query that returns each genre, with the number of tracks sold in the USA:\n\nin absolute numbers\nin percentages.\n\nWrite a paragraph that interprets the data and makes a recommendation for the three artists whose albums we should purchase for the store, based on sales of tracks from their genres.\n\n\nSELECT \n  g.name AS genre,\n  SUM(il.quantity) AS tracks_sold,\n  ROUND(CAST(SUM(il.quantity) AS FLOAT)/\n  (\n    SELECT SUM(il.quantity) \n    FROM invoice i\n    INNER JOIN invoice_line il\n    ON i.invoice_id = il.invoice_id\n    WHERE i.billing_country = 'USA'\n  ) \n  , 4) AS percentage_sold\nFROM invoice i\nINNER JOIN invoice_line il\nON i.invoice_id = il.invoice_id\nINNER JOIN track t \nON il.track_id = t.track_id\nINNER JOIN genre g\nON t.genre_id = g.genre_id\nWHERE i.billing_country = 'USA'\nGROUP BY genre\nORDER BY tracks_sold DESC\n\n\n\n\n\n\ngenre\ntracks_sold\npercentage_sold\n\n\n\n\nRock\n561\n0.5338\n\n\nAlternative & Punk\n130\n0.1237\n\n\nMetal\n124\n0.1180\n\n\nR&B/Soul\n53\n0.0504\n\n\nBlues\n36\n0.0343\n\n\nAlternative\n35\n0.0333\n\n\nPop\n22\n0.0209\n\n\nLatin\n22\n0.0209\n\n\nHip Hop/Rap\n20\n0.0190\n\n\nJazz\n14\n0.0133\n\n\nEasy Listening\n13\n0.0124\n\n\nReggae\n6\n0.0057\n\n\nElectronica/Dance\n5\n0.0048\n\n\nClassical\n4\n0.0038\n\n\nHeavy Metal\n3\n0.0029\n\n\nSoundtrack\n2\n0.0019\n\n\nTV Shows\n1\n0.0010\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_classic())\n\ngenre_of_interest <- c(\"Alternative & Punk\", \"Hip Hop/Rap\", \"Pop\", \"Blues\")\n\ngenre_perc %>% \n  mutate(of_interest = ifelse(genre %in% genre_of_interest, \"yes\", \"no\"),\n         perc_text = scales::percent(percentage_sold, accuracy = 0.1)) %>% \n  ggplot(aes(x=tracks_sold, y=reorder(genre, tracks_sold, sum), fill=of_interest)) + \n  geom_bar(stat = 'identity', width = 0.7) +\n  geom_text(aes(label = perc_text), hjust = -0.2) +\n  labs(title = \"Sold Tracks by Genre, USA\", x = \"Tracks Sold\", y = \"Genre\", \n       fill = \"Genre of Interest\") + \n  scale_fill_manual(values = c(\"gray74\", \"orange\")) +\n  scale_x_continuous(limits = c(0, 600)) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nThe most popular genres in the USA are Rock, Alternative & Punk, and Metal, followed with a big gap by all the others. Since our choice is limited by Hip-Hop, Punk, Pop, and Blues genres, and since we have to choose 3 out of 4 albums, we should purchase the new albums by the following artists:\n\nRed Tone (Punk)\nSlim Jim Bites (Blues)\nMeteor and the Girls (Pop)"
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#analyzing-employee-sales-performance",
    "href": "posts/answering-business-questions-using-sql/chinook.html#analyzing-employee-sales-performance",
    "title": "Answering Business Questions Using SQL",
    "section": "2. Analyzing Employee Sales Performance",
    "text": "2. Analyzing Employee Sales Performance\nEach customer for the Chinook store gets assigned to a sales support agent within the company when they first make a purchase. You have been asked to analyze the purchases of customers belonging to each employee to see if any sales support agent is performing either better or worse than the others.\nYou might like to consider whether any extra columns from the employee table explain any variance you see, or whether the variance might instead be indicative of employee performance.\nInstructions\n\nWrite a query that finds the total dollar amount of sales assigned to each sales support agent within the company. Add any extra attributes for that employee that you find are relevant to the analysis.\nWrite a short statement describing your results, and providing a possible interpretation.\n\n\nSELECT \n  e.first_name || ' ' || e.last_name AS sales_support_agent,\n  e.hire_date,\n  COUNT(DISTINCT c.customer_id) AS customers,\n  SUM(i.total) AS total_sales\nFROM employee e\nINNER JOIN customer c\nON e.employee_id = c.support_rep_id\nINNER JOIN invoice i\nON c.customer_id = i.customer_id\nGROUP BY sales_support_agent\n\n\n3 records\n\n\nsales_support_agent\nhire_date\ncustomers\ntotal_sales\n\n\n\n\nJane Peacock\n2017-04-01 00:00:00\n21\n1731.51\n\n\nMargaret Park\n2017-05-03 00:00:00\n20\n1584.00\n\n\nSteve Johnson\n2017-10-17 00:00:00\n18\n1393.92\n\n\n\n\n\nWhile there is a 20% difference in sales between Jane (the top employee) and Steve (the bottom employee), the difference roughly corresponds with the differences in their hiring dates."
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#analyzing-sales-by-country",
    "href": "posts/answering-business-questions-using-sql/chinook.html#analyzing-sales-by-country",
    "title": "Answering Business Questions Using SQL",
    "section": "3. Analyzing Sales by Country",
    "text": "3. Analyzing Sales by Country\nYour next task is to analyze the sales data for customers from each different country. You have been given guidance to use the country value from the customers table, and ignore the country from the billing address in the invoice table.\nInstructions\n\nWrite a query that collates data on purchases from different countries.\nWhere a country has only one customer, collect them into an “Other” group.\nThe results should be sorted by the total sales from highest to lowest, with the “Other” group at the very bottom.\nFor each country, include:\n\ntotal number of customers\ntotal value of sales\naverage value of sales per customer\naverage order value\n\n\n\nWITH t1 AS (\n  SELECT\n    CASE\n      WHEN COUNT(DISTINCT c.customer_id) = 1 THEN 'Other'\n      ELSE c.country\n      END AS country,\n    COUNT(DISTINCT c.customer_id) AS customers,\n    SUM(i.total) AS total_sales,\n    SUM(i.total)/COUNT(DISTINCT c.customer_id) AS avg_sales_per_cust,\n    AVG(i.total) AS avg_order\n  FROM customer c\n  INNER JOIN invoice i\n  ON c.customer_id = i.customer_id\n  GROUP BY country\n)\n\nSELECT \n  country,\n  SUM(customers) AS customers,\n  SUM(total_sales) AS total_sales,\n  AVG(avg_sales_per_cust) AS avg_sales_per_cust,\n  AVG(avg_order) AS avg_order\nFROM \n  (\n    SELECT\n      t1.*,\n      CASE \n        WHEN country = 'Other' THEN 1\n        ELSE 0\n        END AS sorted\n    FROM t1\n  )\nGROUP BY country\nORDER BY sorted, total_sales DESC\n\n\n\n\n\n\ncountry\ncustomers\ntotal_sales\navg_sales_per_cust\navg_order\n\n\n\n\nUSA\n13\n1040.49\n80.03769\n7.942672\n\n\nCanada\n8\n535.59\n66.94875\n7.047237\n\n\nBrazil\n5\n427.68\n85.53600\n7.011147\n\n\nFrance\n5\n389.07\n77.81400\n7.781400\n\n\nGermany\n4\n334.62\n83.65500\n8.161463\n\n\nCzech Republic\n2\n273.24\n136.62000\n9.108000\n\n\nUnited Kingdom\n3\n245.52\n81.84000\n8.768571\n\n\nPortugal\n2\n185.13\n92.56500\n6.383793\n\n\nIndia\n2\n183.15\n91.57500\n8.721429\n\n\nOther\n15\n1094.94\n72.99600\n7.445071\n\n\n\n\n\n\n\nCode\nsales_by_country %>% \n  select(country, customers, total_sales) %>% \n  mutate(country = factor(country, levels = c(country)) %>% fct_rev()) %>% \n  mutate(customers = customers/sum(customers),\n         total_sales = total_sales/sum(total_sales)) %>%\n  pivot_longer(-country, names_to = \"variable\", values_to = \"value\") %>% \n  ggplot(aes(x=value, y=country, fill=variable)) +\n  geom_bar(stat = \"identity\", width = 0.65, position = position_dodge(0.8)) +\n  labs(title=\"Share of Customers and Sales by Country\", x=\"share\", fill=\"\") +\n  scale_x_continuous(labels = scales::percent) +\n  scale_fill_manual(values = c(\"gray77\", \"seagreen3\")) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nCode\nsales_by_country %>% \n  select(country, avg_order, avg_sales_per_cust) %>% \n  mutate(country = factor(country, levels = c(country)) %>% fct_rev()) %>% \n  mutate(avg_order = (avg_order - mean(avg_order)) / mean(avg_order),\n         avg_sales_per_cust = (avg_sales_per_cust - mean(avg_sales_per_cust)) / \n                                 mean(avg_sales_per_cust)) %>%\n  rename(`Average Order` = avg_order,\n         `Average Sales per Customer` = avg_sales_per_cust) %>% \n  pivot_longer(-country, names_to = \"variable\", values_to = \"pct_diff_from_mean\") %>% \n  ggplot(aes(x=pct_diff_from_mean, y=country, fill=variable)) +\n  geom_col(width = 0.65, position = position_dodge(0.8)) +\n  facet_wrap(~ variable, scales = \"free_x\") + \n  labs(title=\"Average Order & Average Sales per Customer\", \n       subtitle = \"(Percent Difference from Mean)\", x=\"pct diff from mean\", fill=\"\") +\n  scale_fill_manual(values = c(\"steelblue\", \"lightskyblue2\")) +\n  scale_x_continuous(labels = scales::percent) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nThe USA has the largest customer base and, consequently, the highest total sales.\nBased on the data, there may be opportunity in the following countries:\n\nCzech Republic\nUnited Kingdom\nIndia\n\nIt’s worth keeping in mind that the amount of data from each of these countries is relatively low. Because of this, we should be cautious spending too much money on new marketing campaigns, as the sample size is not large enough to give us high confidence. A better approach would be to run small campaigns in these countries, collecting and analyzing the new customers to make sure that these trends hold with new customers."
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#albums-vs-individual-tracks",
    "href": "posts/answering-business-questions-using-sql/chinook.html#albums-vs-individual-tracks",
    "title": "Answering Business Questions Using SQL",
    "section": "4. Albums vs Individual Tracks",
    "text": "4. Albums vs Individual Tracks\nThe Chinook store is setup in a way that allows customer to make purchases in one of the two ways:\n\npurchase a whole album\npurchase a collection of one or more individual tracks.\n\nThe store does not let customers purchase a whole album, and then add individual tracks to that same purchase (unless they do that by choosing each track manually). When customers purchase albums they are charged the same price as if they had purchased each of those tracks separately.\nManagement are currently considering changing their purchasing strategy to save money. The strategy they are considering is to purchase only the most popular tracks from each album from record companies, instead of purchasing every track from an album.\nWe have been asked to find out what percentage of purchases are individual tracks vs whole albums, so that management can use this data to understand the effect this decision might have on overall revenue.\nInstructions\n\nWrite a query that categorizes each invoice as either an album purchase or not, and calculates the following summary statistics:\n\nNumber of invoices\nPercentage of invoices\n\nWrite one to two sentences explaining your findings, and making a prospective recommendation on whether the Chinook store should continue to buy full albums from record companies\n\n\nWITH cat_purchase AS (\n  SELECT\n    il.invoice_id,\n    CASE\n      WHEN\n      COUNT(DISTINCT t.album_id) = 1\n      AND \n      COUNT(DISTINCT t.track_id) = c.count_album_tracks\n      THEN 'album'\n      ELSE 'individual track(s)'\n      END AS purchase_type,\n      c.count_album_tracks\n    FROM track t\n    JOIN invoice_line il\n    ON il.track_id = t.track_id\n    JOIN (SELECT COUNT(*) AS count_album_tracks, album_id\n          FROM track\n          GROUP BY album_id) c\n    ON c.album_id = t.album_id\n    GROUP BY invoice_id\n)\n\nSELECT\n  purchase_type,\n  COUNT(*) AS number_of_invoices,\n  ROUND(CAST(COUNT(*) AS float) / CAST(\n    (SELECT COUNT(*)\n    FROM invoice) AS FLOAT), 2) AS percentage_of_invoices\nFROM cat_purchase\nGROUP BY purchase_type\n\n\n2 records\n\n\npurchase_type\nnumber_of_invoices\npercentage_of_invoices\n\n\n\n\nalbum\n114\n0.19\n\n\nindividual track(s)\n500\n0.81\n\n\n\n\n\nAlbum purchases account for 19% of all purchases. Based on this data, I would recommend against purchasing only the most popular tracks from each album from record companies, since there is a potential of losing a significant portion of revenue."
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#which-artist-is-used-in-the-most-playlists",
    "href": "posts/answering-business-questions-using-sql/chinook.html#which-artist-is-used-in-the-most-playlists",
    "title": "Answering Business Questions Using SQL",
    "section": "5. Which artist is used in the most playlists?",
    "text": "5. Which artist is used in the most playlists?\n\nSELECT \n  ar.name AS artist,\n  g.name AS genre,\n  COUNT(DISTINCT pt.playlist_id) AS number_of_playlists,\n  COUNT(DISTINCT t.track_id) AS unique_tracks\nFROM artist ar\nJOIN album al ON ar.artist_id=al.artist_id\nJOIN track t ON al.album_id=t.album_id\nJOIN playlist_track pt ON pt.track_id = t.track_id\nJOIN genre g ON g.genre_id = t.genre_id\nGROUP BY artist, genre\nORDER BY number_of_playlists DESC, unique_tracks DESC\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\nartist\ngenre\nnumber_of_playlists\nunique_tracks\n\n\n\n\nEugene Ormandy\nClassical\n7\n3\n\n\nBerliner Philharmoniker & Herbert Von Karajan\nClassical\n6\n3\n\n\nThe King’s Singers\nClassical\n6\n2\n\n\nEnglish Concert & Trevor Pinnock\nClassical\n6\n2\n\n\nAcademy of St. Martin in the Fields & Sir Neville Marriner\nClassical\n6\n2\n\n\nMichael Tilson Thomas & San Francisco Symphony\nClassical\n5\n2\n\n\nYo-Yo Ma\nClassical\n5\n1\n\n\nWilhelm Kempff\nClassical\n5\n1\n\n\nTon Koopman\nClassical\n5\n1\n\n\nSir Georg Solti, Sumi Jo & Wiener Philharmoniker\nOpera\n5\n1\n\n\n\n\n\nEugene Ormandy takes the first place with only 3 unique tracks in 7 different playlists. His music belongs to the classical genre, which we have previously seen is one of the least popular genres in the USA.\nIf we order this table by number of unique tracks, we get a completely different list.\n\nSELECT \n  ar.name AS artist,\n  g.name AS genre,\n  COUNT(DISTINCT pt.playlist_id) AS number_of_playlists,\n  COUNT(DISTINCT t.track_id) AS unique_tracks\nFROM artist ar\nJOIN album al ON ar.artist_id=al.artist_id\nJOIN track t ON al.album_id=t.album_id\nJOIN playlist_track pt ON pt.track_id = t.track_id\nJOIN genre g ON g.genre_id = t.genre_id\nGROUP BY artist, genre\nORDER BY unique_tracks DESC, number_of_playlists DESC\n\n\nDisplaying records 1 - 10\n\n\nartist\ngenre\nnumber_of_playlists\nunique_tracks\n\n\n\n\nLed Zeppelin\nRock\n3\n114\n\n\nMetallica\nMetal\n4\n112\n\n\nU2\nRock\n3\n112\n\n\nIron Maiden\nMetal\n4\n95\n\n\nDeep Purple\nRock\n3\n92\n\n\nIron Maiden\nRock\n3\n81\n\n\nPearl Jam\nRock\n4\n54\n\n\nVan Halen\nRock\n3\n52\n\n\nOs Paralamas Do Sucesso\nLatin\n3\n49\n\n\nLost\nTV Shows\n2\n48"
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#how-many-tracks-have-been-purchased-vs-not-purchased",
    "href": "posts/answering-business-questions-using-sql/chinook.html#how-many-tracks-have-been-purchased-vs-not-purchased",
    "title": "Answering Business Questions Using SQL",
    "section": "6. How many tracks have been purchased vs not purchased?",
    "text": "6. How many tracks have been purchased vs not purchased?\n\nWITH all_and_purchased_tracks AS (\n  SELECT \n    t.track_id AS all_tracks,\n    il.track_id AS purch_tracks\n  FROM track t\n  LEFT JOIN invoice_line il\n  ON t.track_id = il.track_id\n)\n  \nSELECT\n  COUNT(DISTINCT all_tracks) AS total_tracks,\n  COUNT(DISTINCT purch_tracks) AS pirchased,\n  COUNT(DISTINCT all_tracks) - COUNT(DISTINCT purch_tracks) AS not_purchased,\n  ROUND(CAST(COUNT(DISTINCT purch_tracks) AS FLOAT)/COUNT(DISTINCT all_tracks), 3)\n    AS perc_purchased,\n  ROUND(CAST(COUNT(DISTINCT all_tracks) - COUNT(DISTINCT purch_tracks) \n    AS FLOAT)/COUNT(DISTINCT all_tracks), 3)\n    AS perc_not_purchased\nFROM all_and_purchased_tracks\n\n\n1 records\n\n\n\n\n\n\n\n\n\ntotal_tracks\npirchased\nnot_purchased\nperc_purchased\nperc_not_purchased\n\n\n\n\n3503\n1806\n1697\n0.516\n0.484\n\n\n\n\n\n\n\nCode\npie(c(51.6, 48.4), labels = c(\"purchased\", \"not purchased\"), \n    main = \"Purchased vs not purchased tracks\")\n\n\n\n\n\nAlmost half of all the unique tracks available in the Chinook store were never bought, probably being of unpopular genre or unpopular artists."
  },
  {
    "objectID": "posts/answering-business-questions-using-sql/chinook.html#do-protected-vs-non-protected-media-types-have-an-effect-on-popularity",
    "href": "posts/answering-business-questions-using-sql/chinook.html#do-protected-vs-non-protected-media-types-have-an-effect-on-popularity",
    "title": "Answering Business Questions Using SQL",
    "section": "7. Do protected vs non-protected media types have an effect on popularity?",
    "text": "7. Do protected vs non-protected media types have an effect on popularity?\nLet’s take a look at the media_type table.\n\nSELECT *\nFROM media_type\n\n\n5 records\n\n\nmedia_type_id\nname\n\n\n\n\n1\nMPEG audio file\n\n\n2\nProtected AAC audio file\n\n\n3\nProtected MPEG-4 video file\n\n\n4\nPurchased AAC audio file\n\n\n5\nAAC audio file\n\n\n\n\n\nThere are 2 out of 5 media types that are protected.\n\nWITH t AS (\n  SELECT \n    t.track_id,\n    CASE\n      WHEN mt.name LIKE \"%protected%\" THEN \"yes\" ELSE \"no\"\n      END AS protected\n  FROM track t\n  JOIN media_type mt ON mt.media_type_id = t.media_type_id\n)\n\nSELECT \n  protected,\n  COUNT(DISTINCT t.track_id) AS unique_tracks,\n  ROUND(CAST(COUNT(DISTINCT t.track_id) AS FLOAT) / (SELECT COUNT(*) FROM track), 2)\n    AS 'unique_tracks_%',\n  COUNT(DISTINCT il.track_id) AS sold_unique_tracks,\n  COUNT(il.track_id) AS sold_tracks,\n  ROUND(CAST(COUNT(il.track_id) AS FLOAT) / (SELECT COUNT(*) FROM invoice_line), 2)\n    AS 'sold_tracks_%'\nFROM t\nLEFT JOIN invoice_line il ON t.track_id = il.track_id\nGROUP BY protected\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprotected\nunique_tracks\nunique_tracks_%\nsold_unique_tracks\nsold_tracks\nsold_tracks_%\n\n\n\n\nno\n3052\n0.87\n1652\n4315\n0.91\n\n\nyes\n451\n0.13\n154\n442\n0.09\n\n\n\n\n\n\n\nCode\nby_media_type %>% \n  select(protected, unique_tracks, sold_tracks) %>% \n  rename(unique = unique_tracks, \n         sold = sold_tracks) %>% \n  pivot_longer(-protected, names_to = \"tracks\", values_to = \"count\") %>% \n  mutate(tracks = as.factor(tracks) %>% fct_rev()) %>% \n  group_by(tracks) %>% \n  mutate(pct = count/sum(count) %>% round(2)) %>% \n  ungroup() %>% \n  ggplot(aes(x=tracks, y=count, fill=protected)) +\n  geom_col(width = 0.5, position = \"stack\", color = \"white\") +\n  geom_text(aes(label = count), position = position_stack(vjust = .5),\n            color = \"white\", fontface = \"bold\")+\n  scale_fill_manual(values = c(\"#fbc02d\", \"#03a9f4\")) +\n  theme(legend.position = \"top\")\nby_media_type %>% \n  select(protected, unique_tracks, sold_unique_tracks) %>% \n  rename(unique = unique_tracks, \n         unique_sold = sold_unique_tracks) %>% \n  mutate(unique_unsold = unique - unique_sold) %>% \n  pivot_longer(-protected, names_to = \"tracks\", values_to = \"count\") %>% \n  filter(tracks != \"unique\") %>% \n  group_by(protected) %>% \n  mutate(percentage = scales::percent(count/sum(count), accuracy = 0.1)) %>% \n  ggplot(aes(x=protected, y=count, fill=tracks)) +\n  geom_col(width = 0.5, position = \"fill\", color = \"white\") +\n  scale_fill_manual(values = c(\"seagreen3\", \"tomato\")) +\n  geom_text(aes(label = percentage), position = position_fill(vjust = .5), \n            color = \"white\", fontface = \"bold\") +\n  labs(y=\"proportion\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n\n\n\nWe can make the following observations:\n\nOnly 13% of all the unique tracks available in the Chinook store are of protected media types.\nAmong all the tracks that were sold, those of protected media types amounts only to 9%.\nFrom all the unique tracks of protected media types, only 34,1% were sold, while from those of non-protected ones 54,1%.\n\nWe can conclude that the tracks of protected media types are much less popular than those of non-protected."
  },
  {
    "objectID": "posts/customer-analysis-advanced-plots-with-ggplot2/customer-analysis-advanced-plots-with-ggplot2.html",
    "href": "posts/customer-analysis-advanced-plots-with-ggplot2/customer-analysis-advanced-plots-with-ggplot2.html",
    "title": "Customer Analysis – Advanced Plots With {ggplot2}",
    "section": "",
    "text": "The Bike Sales Database represents a bicycle manufacturer, including tables for products (bikes), customers (bike shops), and transactions (orders).\nIt consists of 3 tables:\n\nbikes table, which includes bicycle models, descriptions, and unit prices that are produced by the manufacturer.\nbikeshops table, which includes customers that the bicycle manufacturer has sold to.\norderlines table, which includes transactional data such as order ID, order line, date, customer, product, and quantity sold.\n\nbike_sales database is the local Postgres database stored on my machine.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# loading packages\nlibrary(DBI)\nlibrary(RPostgres)  \nlibrary(tidyverse)\nlibrary(lubridate)\n\nThe sql engine uses the DBI package to execute SQL queries, print their results, and optionally assign the results to a data frame. To use the sql engine, we first need to establish a DBI connection to a database.\n\n\n\n\nmycon <- DBI::dbConnect(RPostgres::Postgres(), \n                        dbname = \"bike_sales\", \n                        host = \"localhost\",  \n                        port = \"5432\",  \n                        user = rstudioapi::askForPassword(\"Database username\"),\n                        password = rstudioapi::askForPassword(\"Database password\"))\n\nThere are several options to secure your credentials in R. Here I use prompting for credentials via rstudioapi.\n\nmycon\n\n<PqConnection> bike_sales@localhost:5432\n\n\n\n# list the database table names\ndbListTables(mycon)\n\n[1] \"bikeshops\"  \"bikes\"      \"orderlines\"\n\n\n\n# read the bikeshops table\ndbReadTable(mycon, \"bikeshops\") %>% head()\n\n  bikeshop.id                bikeshop.name       location\n1           1 Pittsburgh Mountain Machines Pittsburgh, PA\n2           2     Ithaca Mountain Climbers     Ithaca, NY\n3           3      Columbus Race Equipment   Columbus, OH\n4           4               Detroit Cycles    Detroit, MI\n5           5             Cincinnati Speed Cincinnati, OH\n6           6    Louisville Race Equipment Louisville, KY\n\n\n\n# read the bikes table\ndbReadTable(mycon, \"bikes\") %>% head()\n\n  bike.id                          model                description price\n1       1        Supersix Evo Black Inc. Road - Elite Road - Carbon 12790\n2       2       Supersix Evo Hi-Mod Team Road - Elite Road - Carbon 10660\n3       3 Supersix Evo Hi-Mod Dura Ace 1 Road - Elite Road - Carbon  7990\n4       4 Supersix Evo Hi-Mod Dura Ace 2 Road - Elite Road - Carbon  5330\n5       5     Supersix Evo Hi-Mod Utegra Road - Elite Road - Carbon  4260\n6       6               Supersix Evo Red Road - Elite Road - Carbon  3940\n\n\n\n# read the orderlines table\ndbReadTable(mycon, \"orderlines\") %>% head()\n\n  order.id order.line order.date customer.id product.id quantity\n1        1          1 2011-01-07           2         48        1\n2        1          2 2011-01-07           2         52        1\n3        2          1 2011-01-10          10         76        1\n4        2          2 2011-01-10          10         52        1\n5        3          1 2011-01-10           6          2        1\n6        3          2 2011-01-10           6         50        1\n\n\n\n# a simple query example\ndbGetQuery(mycon, \n          \"SELECT model, price \n           FROM bikes WHERE price > 10000 \n           ORDER BY price DESC\")\n\n                     model price\n1  Supersix Evo Black Inc. 12790\n2    Scalpel-Si Black Inc. 12790\n3  Habit Hi-Mod Black Inc. 12250\n4          F-Si Black Inc. 11190\n5 Supersix Evo Hi-Mod Team 10660\n\n\n\n\n\nIn all three tables there are dots in column names. This is not a good practice and I first had to figure out how to join the tables without an error! Here is the solution:\n\nbike_orderlines_joined <- dbGetQuery(mycon, \n\n'SELECT * \nFROM orderlines \nLEFT JOIN bikes\nON orderlines.\"product.id\" = bikes.\"bike.id\"\nLEFT JOIN bikeshops\nON orderlines.\"customer.id\" = bikeshops.\"bikeshop.id\"')\n\nhead(bike_orderlines_joined)\n\n  order.id order.line order.date customer.id product.id quantity bike.id\n1        1          1 2011-01-07           2         48        1      48\n2        1          2 2011-01-07           2         52        1      52\n3        2          1 2011-01-10          10         76        1      76\n4        2          2 2011-01-10          10         52        1      52\n5        3          1 2011-01-10           6          2        1       2\n6        3          2 2011-01-10           6         50        1      50\n                     model                       description price bikeshop.id\n1          Jekyll Carbon 2 Mountain - Over Mountain - Carbon  6070           2\n2         Trigger Carbon 2 Mountain - Over Mountain - Carbon  5970           2\n3      Beast of the East 1       Mountain - Trail - Aluminum  2770          10\n4         Trigger Carbon 2 Mountain - Over Mountain - Carbon  5970          10\n5 Supersix Evo Hi-Mod Team        Road - Elite Road - Carbon 10660           6\n6          Jekyll Carbon 4 Mountain - Over Mountain - Carbon  3200           6\n              bikeshop.name        location\n1  Ithaca Mountain Climbers      Ithaca, NY\n2  Ithaca Mountain Climbers      Ithaca, NY\n3         Kansas City 29ers Kansas City, KS\n4         Kansas City 29ers Kansas City, KS\n5 Louisville Race Equipment  Louisville, KY\n6 Louisville Race Equipment  Louisville, KY\n\n\n\nglimpse(bike_orderlines_joined)\n\nRows: 15,644\nColumns: 13\n$ order.id      <dbl> 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,…\n$ order.line    <dbl> 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1,…\n$ order.date    <date> 2011-01-07, 2011-01-07, 2011-01-10, 2011-01-10, 2011-01…\n$ customer.id   <dbl> 2, 2, 10, 10, 6, 6, 6, 6, 6, 22, 8, 8, 8, 8, 16, 16, 16,…\n$ product.id    <dbl> 48, 52, 76, 52, 2, 50, 1, 4, 34, 26, 96, 66, 35, 72, 45,…\n$ quantity      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,…\n$ bike.id       <dbl> 48, 52, 76, 52, 2, 50, 1, 4, 34, 26, 96, 66, 35, 72, 45,…\n$ model         <chr> \"Jekyll Carbon 2\", \"Trigger Carbon 2\", \"Beast of the Eas…\n$ description   <chr> \"Mountain - Over Mountain - Carbon\", \"Mountain - Over Mo…\n$ price         <dbl> 6070, 5970, 2770, 5970, 10660, 3200, 12790, 5330, 1570, …\n$ bikeshop.id   <dbl> 2, 2, 10, 10, 6, 6, 6, 6, 6, 22, 8, 8, 8, 8, 16, 16, 16,…\n$ bikeshop.name <chr> \"Ithaca Mountain Climbers\", \"Ithaca Mountain Climbers\", …\n$ location      <chr> \"Ithaca, NY\", \"Ithaca, NY\", \"Kansas City, KS\", \"Kansas C…\n\n\nDisconnecting from the database.\n\ndbDisconnect(mycon)\n\n\n\n\n\nbike_orderlines <- bike_orderlines_joined %>% \n  # rename columns - replacing \".\" with \"_\"\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\")) %>% \n  # remove the unnecessary columns \n  select(-c(customer_id, product_id, bike_id, bikeshop_id)) %>% \n  # separate description into category_1, category_2, and frame_material\n  separate(description, \n           c(\"category_1\", \"category_2\", \"frame_material\"),\n           sep = \" - \") %>% \n  # separate location into city and state\n  separate(location,\n           c(\"city\", \"state\"),\n           sep = \", \") %>%\n  # create a new column total_price\n  mutate(total_price = price * quantity) %>% \n  # reorder columns\n  select(contains(c(\"date\", \"id\", \"order\")),\n         quantity, price, total_price,\n         everything()) \n\nbike_orderlines %>% head()\n\n  order_date order_id order_line quantity price total_price\n1 2011-01-07        1          1        1  6070        6070\n2 2011-01-07        1          2        1  5970        5970\n3 2011-01-10        2          1        1  2770        2770\n4 2011-01-10        2          2        1  5970        5970\n5 2011-01-10        3          1        1 10660       10660\n6 2011-01-10        3          2        1  3200        3200\n                     model category_1    category_2 frame_material\n1          Jekyll Carbon 2   Mountain Over Mountain         Carbon\n2         Trigger Carbon 2   Mountain Over Mountain         Carbon\n3      Beast of the East 1   Mountain         Trail       Aluminum\n4         Trigger Carbon 2   Mountain Over Mountain         Carbon\n5 Supersix Evo Hi-Mod Team       Road    Elite Road         Carbon\n6          Jekyll Carbon 4   Mountain Over Mountain         Carbon\n              bikeshop_name        city state\n1  Ithaca Mountain Climbers      Ithaca    NY\n2  Ithaca Mountain Climbers      Ithaca    NY\n3         Kansas City 29ers Kansas City    KS\n4         Kansas City 29ers Kansas City    KS\n5 Louisville Race Equipment  Louisville    KY\n6 Louisville Race Equipment  Louisville    KY\n\n\n\nbike_orderlines %>% glimpse()\n\nRows: 15,644\nColumns: 13\n$ order_date     <date> 2011-01-07, 2011-01-07, 2011-01-10, 2011-01-10, 2011-0…\n$ order_id       <dbl> 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7…\n$ order_line     <dbl> 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1…\n$ quantity       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1…\n$ price          <dbl> 6070, 5970, 2770, 5970, 10660, 3200, 12790, 5330, 1570,…\n$ total_price    <dbl> 6070, 5970, 2770, 5970, 10660, 3200, 12790, 5330, 1570,…\n$ model          <chr> \"Jekyll Carbon 2\", \"Trigger Carbon 2\", \"Beast of the Ea…\n$ category_1     <chr> \"Mountain\", \"Mountain\", \"Mountain\", \"Mountain\", \"Road\",…\n$ category_2     <chr> \"Over Mountain\", \"Over Mountain\", \"Trail\", \"Over Mounta…\n$ frame_material <chr> \"Carbon\", \"Carbon\", \"Aluminum\", \"Carbon\", \"Carbon\", \"Ca…\n$ bikeshop_name  <chr> \"Ithaca Mountain Climbers\", \"Ithaca Mountain Climbers\",…\n$ city           <chr> \"Ithaca\", \"Ithaca\", \"Kansas City\", \"Kansas City\", \"Loui…\n$ state          <chr> \"NY\", \"NY\", \"KS\", \"KS\", \"KY\", \"KY\", \"KY\", \"KY\", \"KY\", \"…"
  },
  {
    "objectID": "posts/customer-analysis-advanced-plots-with-ggplot2/customer-analysis-advanced-plots-with-ggplot2.html#lollipop-chart-top-n-customers",
    "href": "posts/customer-analysis-advanced-plots-with-ggplot2/customer-analysis-advanced-plots-with-ggplot2.html#lollipop-chart-top-n-customers",
    "title": "Customer Analysis – Advanced Plots With {ggplot2}",
    "section": "Lollipop Chart: Top N Customers",
    "text": "Lollipop Chart: Top N Customers\nQuestion: How much purchasing power is in top 10 customers?\nGoal is to visualize top N customers in terms of Revenue, including cumulative percentage.\n\nData manipulation\n\nn <- 10\n\ntop_customers <- bike_orderlines %>% \n  select(bikeshop_name, total_price) %>% \n  mutate(bikeshop_name = as_factor(bikeshop_name) %>% fct_lump_n(n = n, w = total_price)) %>% \n  group_by(bikeshop_name) %>% \n  summarise(revenue = sum(total_price)) %>% \n  ungroup() %>% \n  mutate(bikeshop_name = bikeshop_name %>% fct_reorder(revenue)) %>% \n  mutate(bikeshop_name = bikeshop_name %>% fct_relevel(\"Other\", after = 0)) %>% \n  arrange(desc(bikeshop_name)) %>% \n  # revenue text\n  mutate(revenue_text = scales::dollar(revenue, scale = 1e-06, suffix = \"M\")) %>% \n  # cumulative percent\n  mutate(cum_pct = cumsum(revenue) / sum(revenue)) %>% \n  mutate(cum_pct_text = scales::percent(cum_pct)) %>% \n  # rank\n  mutate(rank = row_number()) %>% \n  mutate(rank = ifelse(rank == max(rank), NA_integer_, rank)) %>% \n  # label text\n  mutate(label_text = str_glue(\"Rank: {rank}\\nRev: {revenue_text}\\nCumPct: {cum_pct_text}\")) \n\ntop_customers\n\n# A tibble: 11 × 7\n   bikeshop_name                 revenue revenue…¹ cum_pct cum_p…²  rank label…³\n   <fct>                           <dbl> <chr>       <dbl> <chr>   <int> <glue> \n 1 Kansas City 29ers            11535455 $11.54M     0.162 16.2%       1 Rank: …\n 2 Denver Bike Shop              7697670 $7.70M      0.271 27.1%       2 Rank: …\n 3 Ithaca Mountain Climbers      6299335 $6.30M      0.359 35.9%       3 Rank: …\n 4 Phoenix Bi-peds               4168535 $4.17M      0.418 41.8%       4 Rank: …\n 5 Oklahoma City Race Equipment  3450040 $3.45M      0.467 46.7%       5 Rank: …\n 6 Las Vegas Cycles              3073615 $3.07M      0.510 51.0%       6 Rank: …\n 7 New Orleans Velocipedes       2761825 $2.76M      0.549 54.9%       7 Rank: …\n 8 Wichita Speed                 2380385 $2.38M      0.582 58.2%       8 Rank: …\n 9 Miami Race Equipment          2057130 $2.06M      0.611 61.1%       9 Rank: …\n10 Minneapolis Bike Shop         2023220 $2.02M      0.640 64.0%      10 Rank: …\n11 Other                        25585120 $25.59M     1     100.0%     NA Rank: …\n# … with abbreviated variable names ¹​revenue_text, ²​cum_pct_text, ³​label_text\n\n\n\n\nData visualization\n\ntop_customers %>% \n  ggplot(aes(revenue, bikeshop_name)) +\n  # geometries\n  geom_segment(aes(xend = 0, yend = bikeshop_name), \n               color = RColorBrewer::brewer.pal(n = 9, name = \"Set1\")[1],\n               size = 1) +\n  geom_point(color = RColorBrewer::brewer.pal(n = 9, name = \"Set1\")[1], \n             size = 3) +\n  geom_label(aes(label = label_text), \n             hjust = \"left\", \n             size = 3,\n             nudge_x = 0.8e+06) +\n  # formatting\n  scale_x_continuous(labels = scales::dollar_format(scale = 1e-06, suffix = \"M\")) +\n  labs(title = str_glue(\"Top {n} customers in terms of revenue, with cumulative percentage\"),\n       subtitle = str_glue(\"Top {n} customers contribute {top_customers$cum_pct_text[n]} of purchasing power.\"),\n       x = \"Revenue ($M)\",\n       y = \"Customer\",\n       caption = str_glue(\"Year: {year(min(bike_orderlines$order_date))} - {year(max(bike_orderlines$order_date))}\")) +\n  expand_limits(x = max(top_customers$revenue) + 6e+06) +\n  # theme\n  theme_bw() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank())"
  },
  {
    "objectID": "posts/customer-analysis-advanced-plots-with-ggplot2/customer-analysis-advanced-plots-with-ggplot2.html#heatmap-customers-purchasing-habits",
    "href": "posts/customer-analysis-advanced-plots-with-ggplot2/customer-analysis-advanced-plots-with-ggplot2.html#heatmap-customers-purchasing-habits",
    "title": "Customer Analysis – Advanced Plots With {ggplot2}",
    "section": "Heatmap: Customers’ Purchasing Habits",
    "text": "Heatmap: Customers’ Purchasing Habits\nQuestion: Do specific customers have a purchasing preference?\nGoal is to visualize heatmap of proportion of sales by Secondary Product Category.\n\nData manipulation\n\npct_sales_by_customer <- bike_orderlines %>% \n  select(bikeshop_name, category_1, category_2, quantity) %>% \n  group_by(bikeshop_name, category_1, category_2) %>% \n  summarise(total_qty = sum(quantity)) %>% \n  ungroup() %>% \n  group_by(bikeshop_name) %>% \n  mutate(pct = total_qty / sum(total_qty)) %>% \n  ungroup() %>% \n  mutate(bikeshop_name = as.factor(bikeshop_name) %>% fct_rev()) %>%  \n  mutate(bikeshop_name_num = as.numeric(bikeshop_name))\n    \npct_sales_by_customer   \n\n# A tibble: 270 × 6\n   bikeshop_name      category_1 category_2         total_qty    pct bikeshop_…¹\n   <fct>              <chr>      <chr>                  <dbl>  <dbl>       <dbl>\n 1 Albuquerque Cycles Mountain   Cross Country Race        48 0.168           30\n 2 Albuquerque Cycles Mountain   Fat Bike                   9 0.0315          30\n 3 Albuquerque Cycles Mountain   Over Mountain             13 0.0455          30\n 4 Albuquerque Cycles Mountain   Sport                     35 0.122           30\n 5 Albuquerque Cycles Mountain   Trail                     38 0.133           30\n 6 Albuquerque Cycles Road       Cyclocross                 7 0.0245          30\n 7 Albuquerque Cycles Road       Elite Road                69 0.241           30\n 8 Albuquerque Cycles Road       Endurance Road            54 0.189           30\n 9 Albuquerque Cycles Road       Triathalon                13 0.0455          30\n10 Ann Arbor Speed    Mountain   Cross Country Race        32 0.0532          29\n# … with 260 more rows, and abbreviated variable name ¹​bikeshop_name_num\n\n\n\n\nData visualization\n\npct_sales_by_customer %>% \n  ggplot(aes(category_2, bikeshop_name)) + \n  # geometries\n  geom_tile(aes(fill = pct)) +\n  geom_text(aes(label = scales::percent(pct, accuracy = 0.1)),\n            size = 3,\n            color = ifelse(pct_sales_by_customer$pct >= 0.15, \"white\", \"black\")) +\n  facet_wrap(~ category_1, scales = \"free_x\") + \n  # formatting\n  scale_fill_gradient(low = \"white\", high = tidyquant::palette_light()[1]) + \n  labs(title = \"Heatmap of Purchasing Habits\", \n       subtitle = str_glue(\"Year: {year(min(bike_orderlines$order_date))} - {year(max(bike_orderlines$order_date))}\"),\n       x = \"Bike Type\",\n       y = \"Customer\") + \n  # theme\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(face = \"bold\"),\n        strip.background = element_rect(fill = tidyquant::palette_light()[1], \n                                        color = \"white\"), \n        strip.text = element_text(color = \"white\", size = 11), \n        panel.background = element_rect(fill = \"white\"))\n\n\n\n\nTop 3 customers that prefer mountain bikes:\n\nIthaca Mountain Climbers\nPittsburgh Mountain Machines\nTampa 29ers\n\nTop 3 customers that prefer road bikes:\n\nAnn Arbor Speed\nAustin Cruisers\nIndianapolis Velocipedes\n\n\nThat’s it! I hope you like it. For those wondering where I learned to make plots like this… in a fabulous course Data Science for Business Part 1 by Matt Dancho. This is probably the best course on R and I highly recommend it."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html",
    "title": "Titanic Survival Exercises",
    "section": "",
    "text": "After auditing the HarvardX’s Data Science: Visualization course I’ve found this assessment way too interesting and fun. So I decided to put all my new skills together to perform exploratory data analysis on a classic machine learning dataset: Titanic survival! My goal is to provide answers entirely through visualizations."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#background",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#background",
    "title": "Titanic Survival Exercises",
    "section": "Background",
    "text": "Background\nThe Titanic was a British ocean liner that struck an iceberg and sunk on its maiden voyage in 1912 from the United Kingdom to New York. More than 1,500 of the estimated 2,224 passengers and crew died in the accident, making this one of the largest maritime disasters ever outside of war. The ship carried a wide range of passengers of all ages and both genders, from luxury travelers in first-class to immigrants in the lower classes. However, not all passengers were equally likely to survive the accident. We use real data about a selection of 891 passengers to learn who was on the Titanic and which passengers were more likely to survive."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#libraries-customizations-and-data",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#libraries-customizations-and-data",
    "title": "Titanic Survival Exercises",
    "section": "Libraries, Customizations, and Data",
    "text": "Libraries, Customizations, and Data\n\nlibrary(tidyverse)\nlibrary(titanic)\n\noptions(digits = 3)  \ntheme_set(theme_classic())\ncolors_sex <- c(\"mediumorchid1\", \"dodgerblue\")\ncolors_survived <- c(\"gray65\", \"lightgreen\")\n\nDefining the titanic dataset.\n\ntitanic <- titanic_train %>%\n  select(Survived, Pclass, Sex, Age, SibSp, Parch, Fare) %>%\n  mutate(Survived = factor(Survived),\n         Pclass = factor(Pclass),\n         Sex = factor(Sex))\n\nhead(titanic)\n\n  Survived Pclass    Sex Age SibSp Parch  Fare\n1        0      3   male  22     1     0  7.25\n2        1      1 female  38     1     0 71.28\n3        1      3 female  26     0     0  7.92\n4        1      1 female  35     1     0 53.10\n5        0      3   male  35     0     0  8.05\n6        0      3   male  NA     0     0  8.46\n\nstr(titanic)\n\n'data.frame':   891 obs. of  7 variables:\n $ Survived: Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 1 1 1 2 2 ...\n $ Pclass  : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 1 3 1 3 3 1 3 3 2 ...\n $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n $ Age     : num  22 38 26 35 35 NA 54 2 27 14 ...\n $ SibSp   : int  1 1 0 1 0 0 0 3 0 1 ...\n $ Parch   : int  0 0 0 0 0 0 0 1 2 0 ...\n $ Fare    : num  7.25 71.28 7.92 53.1 8.05 ..."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-1-variable-types",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-1-variable-types",
    "title": "Titanic Survival Exercises",
    "section": "Question 1: Variable Types",
    "text": "Question 1: Variable Types\nInstructions: Inspect the data and also use ?titanic_train to learn more about the variables in the dataset. Match these variables from the dataset to their variable type. There is at least one variable of each type (ordinal categorical, non-ordinal (nominal) categorical, continuous, discrete).\nChecking if Age variable is discrete or continuous…\n\nunique(titanic$Age)\n\n [1] 22.00 38.00 26.00 35.00    NA 54.00  2.00 27.00 14.00  4.00 58.00 20.00\n[13] 39.00 55.00 31.00 34.00 15.00 28.00  8.00 19.00 40.00 66.00 42.00 21.00\n[25] 18.00  3.00  7.00 49.00 29.00 65.00 28.50  5.00 11.00 45.00 17.00 32.00\n[37] 16.00 25.00  0.83 30.00 33.00 23.00 24.00 46.00 59.00 71.00 37.00 47.00\n[49] 14.50 70.50 32.50 12.00  9.00 36.50 51.00 55.50 40.50 44.00  1.00 61.00\n[61] 56.00 50.00 36.00 45.50 20.50 62.00 41.00 52.00 63.00 23.50  0.92 43.00\n[73] 60.00 10.00 64.00 13.00 48.00  0.75 53.00 57.00 80.00 70.00 24.50  6.00\n[85]  0.67 30.50  0.42 34.50 74.00\n\n\nAge is a continuous variable.\n\n\n\nVariable\nDescription\nVariable Type\n\n\n\n\nSurvived\nPassenger Survival Indicator\nnominal categorical\n\n\nPclass\nPassenger Class\nordinal categorical\n\n\nSex\nSex\nnominal categorical\n\n\nAge\nAge\ncontinuous\n\n\nSibSp\nNumber of Siblings/Spouses Aboard\ndiscrete\n\n\nParch\nNumber of Parents/Children Aboard\ndiscrete\n\n\nFare\nPassenger Fare\ncontinuous"
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-2-demographics-of-titanic-passengers",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-2-demographics-of-titanic-passengers",
    "title": "Titanic Survival Exercises",
    "section": "Question 2: Demographics of Titanic Passengers",
    "text": "Question 2: Demographics of Titanic Passengers\nInstructions: Make density plots of age grouped by sex. Try experimenting with combinations of faceting, alpha blending, stacking and using variable counts on the y-axis to answer the following questions. Some questions may be easier to answer with different versions of the density plot.\n\ntitanic %>% \n  ggplot(aes(Age)) +\n  geom_density(aes(color = Sex), size = 0.7) +\n  scale_color_manual(values = colors_sex) +\n  geom_vline(xintercept = c(18, 35), linetype = 2) +\n  geom_text(aes(x = 18, y = 0.031, label= \"18\", hjust = 1.5)) +\n  geom_text(aes(x = 35, y = 0.031, label= \"35\", hjust = -0.5)) +\n  theme(legend.position = \"top\") +\n  ylab(\"density\")\n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Age, fill = Sex)) +\n  geom_density(alpha = 0.3) +\n  scale_fill_manual(values = colors_sex) +\n  geom_vline(xintercept = 17, linetype = 2) +\n  geom_text(aes(x = 17, y = 0.031, label= \"17\", hjust = 1.5)) +\n  theme(legend.position = \"top\") +\n  ylab(\"density\")\n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Age, ..count.., fill = Sex)) +\n  geom_density(alpha = 0.7) +\n  facet_grid(Sex ~ .) +\n  scale_fill_manual(values = colors_sex) +\n  geom_vline(xintercept = 40, linetype = 2) + \n  geom_text(aes(x = 40, y = 14, label= \"40\", hjust = -0.5)) +\n  theme(legend.position = \"top\")\n\n\n\n\nWhich of the following are true?\nSelect all correct answers\n\n✅ Females and males had the same general shape of age distribution.\n✅ } The age distribution was bimodal, with one mode around 25 years of age and a second - - smaller mode around 5 years of age.\n❌ There were more females than males.\n✅ The count of males of age 40 was higher than the count of females of age 40.\n✅ The proportion of males age 18-35 was higher than the proportion of females age 18-35.\n✅ The proportion of females under age 17 was higher than the proportion of males under age 17.\n❌ The oldest passengers were female."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-3-qq-plot-of-age-distribution",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-3-qq-plot-of-age-distribution",
    "title": "Titanic Survival Exercises",
    "section": "Question 3: QQ-plot of Age Distribution",
    "text": "Question 3: QQ-plot of Age Distribution\nInstructions: Use geom_qq() to make a QQ-plot of passenger age and add an identity line with geom_abline(). Filter out any individuals with an age of NA first.\n\nparams <- titanic %>%\n  filter(!is.na(Age)) %>%\n  summarize(mean = mean(Age), sd = sd(Age))\n\nparams\n\n  mean   sd\n1 29.7 14.5\n\ntitanic %>% ggplot(aes(sample = Age)) + \n  geom_qq(dparams = params) +\n  geom_abline()\n\n\n\n\nWhich of the following is the correct plot according to the instructions above?\n\n✅ The plot above."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-4-survival-by-sex",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-4-survival-by-sex",
    "title": "Titanic Survival Exercises",
    "section": "Question 4: Survival by Sex",
    "text": "Question 4: Survival by Sex\nInstructions: To answer the following questions, make barplots of the Survived and Sex variables using geom_bar(). Try plotting one variable and filling by the other variable. You may want to try the default plot, then try adding position = position_dodge() to geom_bar() to make separate bars for each group.\n\ntitanic %>% \n  ggplot(aes(Survived, fill = Sex)) +\n  geom_bar(width = 0.7, color = \"white\") +\n  scale_fill_manual(values = colors_sex)\n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Sex, fill = Survived)) +\n  geom_bar(width =  0.8, position = position_dodge(0.85)) +\n  scale_fill_manual(values = colors_survived)\n\n\n\n\nWhich of the following are true?\nSelect all correct answers.\n\n✅ Less than half of passengers survived.\n✅ Most of the survivors were female.\n❌ Most of the males survived.\n✅ Most of the females survived."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-5-survival-by-age",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-5-survival-by-age",
    "title": "Titanic Survival Exercises",
    "section": "Question 5: Survival by Age",
    "text": "Question 5: Survival by Age\nInstructions: Make a density plot of age filled by survival status. Change the y-axis to count and set alpha = 0.2.\nThe following answers were offered for all three questions:\n\n0-8\n10-18\n18-30\n30-50\n50-70\n70-80\n\n\nWhich age group is the only group more likely to survive than die?\n\ntitanic %>% \n  ggplot(aes(Age, y = ..count.., fill = Survived)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = colors_survived) +\n  geom_vline(xintercept = 8, linetype = 2) +\n  geom_text(aes(x = 8, y = 14, label= \"8\", hjust = -0.5))\n\n\n\n\n\n✅ Age group 0-8.\n\n\n\nWhich age group had the most deaths?\nIt’s hard to tell from the previews plot I’ll have to make a new column Age group based on the offered answers.\n\ntitanic2 <- titanic %>%\n  filter(!is.na(Age)) %>% \n  mutate(`Age group` = case_when(\n    Age >0 & Age <=8 ~ \"0-8\",\n    Age >=10 & Age <=18 ~ \"10-18\",\n    Age >=18 & Age <=30 ~ \"18-30\",\n    Age >=30 & Age <=50 ~ \"30-50\",\n    Age >=50 & Age <=70 ~ \"50-70\",\n    Age >=70 & Age <=80 ~ \"70-80\"))\n\n\ntitanic2 %>% \n  filter(!is.na(`Age group`)) %>% \n  ggplot(aes(`Age group`, fill = Survived)) + \n  geom_bar(width = 0.7, color = \"white\") +\n  scale_fill_manual(values = colors_survived)\n\n\n\n\n\n✅ Age group 18-30.\n\n\n\nWhich age group had the highest proportion of deaths?\n\ntitanic2 %>% \n  filter(!is.na(`Age group`)) %>% \n  ggplot(aes(`Age group`, fill = Survived)) + \n  geom_bar(position = \"fill\", width = 0.7, color = \"white\") +\n  scale_fill_manual(values = colors_survived)\n\n\n\n\n\n✅ Age group 70-80"
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-6-survival-by-fare",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-6-survival-by-fare",
    "title": "Titanic Survival Exercises",
    "section": "Question 6: Survival by Fare",
    "text": "Question 6: Survival by Fare\nInstructions: Filter the data to remove individuals who paid a fare of 0. Make a boxplot of fare grouped by survival status. Try a log2 transformation of fares. Add the data points with jitter and alpha blending.\n\nset.seed(123)\n\ntitanic %>% filter(Fare != 0) %>% \n  ggplot(aes(Survived, Fare)) +\n  geom_boxplot(fill = colors_survived, width = 0.5, alpha = 0.5) + \n  geom_jitter(width = 0.1, alpha = 0.2) +\n  scale_y_continuous(trans = \"log2\")\n\n\n\n\nWhich of the following are true?\nSelect all correct answers.\n\n✅ Passengers who survived generally payed higher fares than those who did not survive.\n❌ The interquartile range for fares was smaller for passengers who survived.\n✅ The median fare was lower for passengers who did not survive.\n❌ Only one individual paid a fare around $500. That individual survived. (3 individuals survived)\n✅ Most individuals who paid a fare around $8 did not survive."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-7-survival-by-passenger-class",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-7-survival-by-passenger-class",
    "title": "Titanic Survival Exercises",
    "section": "Question 7: Survival by Passenger Class",
    "text": "Question 7: Survival by Passenger Class\nInstructions: The Pclass variable corresponds to the passenger class. Make three barplots. For the first, make a basic barplot of passenger class filled by survival. For the second, make the same barplot but use the argument position = position_fill() to show relative proportions in each group instead of counts. For the third, make a barplot of survival filled by passenger class using position = position_fill()\n\ntitanic %>% \n  ggplot(aes(Pclass, fill = Pclass)) + \n  geom_bar(width = 0.7) +\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -1) +\n  expand_limits(y = 530) +\n  ylab(\"count\")\n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Pclass, fill = Survived)) + \n  geom_bar(width = 0.7, position = position_fill(), color = \"white\") +\n  scale_fill_manual(values = colors_survived)\n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Pclass, fill = Survived)) + \n  geom_bar(width = 0.8, position = position_dodge(0.85)) +\n  scale_fill_manual(values = colors_survived)\n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Survived, fill = Pclass)) + \n  geom_bar(width = 0.7, position = position_fill(), color = \"white\") \n\n\n\n\nWhich of the following are true?\nSelect all correct answers.\n\n✅ There were more third class passengers than passengers in the first two classes combined.\n❌ There were the fewest passengers in first class, second-most passengers in second class, and most passengers in third class.\n✅ Survival proportion was highest for first class passengers, followed by second class. Third-class had the lowest survival proportion.\n✅ Most passengers in first class survived. Most passengers in other classes did not survive.\n❌ The majority of survivors were from first class.\n✅ The majority of those who did not survive were from third class."
  },
  {
    "objectID": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-8-survival-by-age-sex-and-passenger-class",
    "href": "posts/titanic-survival-exercises/titanic-survival-exercises.html#question-8-survival-by-age-sex-and-passenger-class",
    "title": "Titanic Survival Exercises",
    "section": "Question 8: Survival by Age, Sex and Passenger Class",
    "text": "Question 8: Survival by Age, Sex and Passenger Class\nInstructions: Create a grid of density plots for age, filled by survival status, with count on the y-axis, faceted by sex and passenger class.\n\ntitanic %>% \n  ggplot(aes(Age, ..count.., fill = Pclass)) +\n  geom_density(alpha=0.5) \n\n\n\n\n\ntitanic %>% \n  ggplot(aes(Age, ..count.., fill = Survived)) +\n  geom_density(alpha=0.5) +\n  facet_grid((Sex ~ Pclass)) +\n  scale_fill_manual(values = colors_survived) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA)) +\n  theme(legend.position = \"top\")\n\n\n\n\nWhich of the following are true?\nSelect all correct answers.\n\n✅ The largest group of passengers was third-class males.\n❌ The age distribution is the same across passenger classes.\n❌ The gender distribution is the same across passenger classes.\n✅ Most first-class and second-class females survived.\n✅ Almost all second-class males did not survive, with the exception of children.\n\n\nThat’s all. Thanks for reading!"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "",
    "text": "The goal of this project is to scrape data on the 200 best movies of the last decade from the Rotten Tomatoes website with the R rvest package, and finally create a dashboard in Tableau. The idea is to show all the movies in one place. Hovering over the movie should reveal relevant data in the tooltip for quick overview. Clicking on the movie should open the movie’s website for more information.\nI’ve learned so much while working on this project (like web scraping, writing functions, iteration, …). The purrr package for functional programming is super-cool. It allows iteration with just one line of code (a very handy replacement for for loops).\nI hope you’ll enjoy the process as much as I did. At times it was quite challenging, but that’s how we learn!\n\n\n\n# loading packages\nlibrary(tidyverse)\nlibrary(rvest)\n\nAre we allowed to scrape data from the Rotten Tomatoes website?\n\nrobotstxt::paths_allowed(\"https://www.rottentomatoes.com/\")\n\n[1] TRUE"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#plan",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#plan",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "Plan",
    "text": "Plan\nThe data will be scraped from this page. Since it doesn’t contain all the data I am interested in, I have to visit every movie’s web page on the list and scrape data from there. Here is the plan:\n\nScrape data from the main page: the urls of movies, and the urls of images.\nScrape title, year_genre_runtime, critics_score, audiaece_score, and synopsis from the first movie to develop the code.\nWrite a function that scrapes data based on movie’s URL.\nIteration - use this function to scrape data from each individual movie and create a data frame with the columns title, year_genre_runtime, critics_score, audiaece_score, synopsis, and url.\nDownload images\nPrepare data for Tableau\nCreate a dashboard in Tableau"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#scraping-data-from-the-main-page",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#scraping-data-from-the-main-page",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "1. Scraping data from the main page",
    "text": "1. Scraping data from the main page\nReading the main page with read_html().\n\nmain_url <- \"https://editorial.rottentomatoes.com/guide/the-200-best-movies-of-the-2010s/\"\nmain_page <- read_html(main_url)\n\n\n\n\n\n\n\nFigure 1: The main page\n\n\n\n\nI make use of the SelectorGadget to identify the tags for the relevant nodes. Here is the link for Chrome (recommended).\n\nExtracting urls of movies\nThe same nodes that contain the text for the titles also contain information on the links to individual movie pages for each title. We can extract this information using the html_attr() function, which extracts attributes.\n\nmovie_urls <- main_page %>% \n  html_nodes(\".article_movie_title a\") %>% \n  html_attr(\"href\")\n\nmovie_urls %>% head()\n\n[1] \"https://www.rottentomatoes.com/m/12_years_a_slave\"    \n[2] \"https://www.rottentomatoes.com/m/20_feet_from_stardom\"\n[3] \"https://www.rottentomatoes.com/m/45_years\"            \n[4] \"https://www.rottentomatoes.com/m/all_is_lost_2013\"    \n[5] \"https://www.rottentomatoes.com/m/amazing_grace_2018\"  \n[6] \"https://www.rottentomatoes.com/m/american_hustle\"     \n\n\n\n\nExtracting urls of images\n\nimage_urls <- main_page %>% \n  html_nodes(\".article_poster\") %>% \n  html_attr(\"src\")\n\nLet’s check the image for the 6th title.\n\nknitr::include_graphics(image_urls[6])"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#scraping-data-for-the-first-movie-on-the-list",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#scraping-data-for-the-first-movie-on-the-list",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "2. Scraping data for the first movie on the list",
    "text": "2. Scraping data for the first movie on the list\nNow I’m going to scrape data for the movie 12 Years a Slave in order to develop the code.\nReading page for the first movie.\n\nurl <- \"https://www.rottentomatoes.com/m/12_years_a_slave\"\nmovie_page <- read_html(url)\n\n\n\n\n\n\n\nFigure 2: Title, year, genre, runtime, critics and audience score\n\n\n\n\nScroll down the page and you’ll find the movie synopsis.\n\n\n\n\n\nFigure 3: Synopsis\n\n\n\n\n\nExtracting title\n\ntitle <- movie_page %>% \n  html_node(\".scoreboard__title\") %>% \n  html_text()\n\ntitle\n\n[1] \"12 Years a Slave\"\n\n\n\n\nExtracting year, genre, and runtime\n\nyear_genre_runtime <- movie_page %>% \n  html_node(\".scoreboard__info\") %>% \n  html_text()\n\nyear_genre_runtime\n\n[1] \"2013, History/Drama, 2h 14m\"\n\n\n\n\nExtracting critics score\nThe next two are tricky. I had to look at the page source and find them manually.\n\ncritics_score <- movie_page %>% \n  html_element(\"score-board\") %>% \n  html_attr(\"tomatometerscore\") %>% \n  str_c(.,\"%\")\n\ncritics_score\n\n[1] \"95%\"\n\n\n\n\nExtracting audience score\n\naudience_score <- movie_page %>% \n  html_element(\"score-board\") %>% \n  html_attr(\"audiencescore\") %>% \n  str_c(.,\"%\")\n\naudience_score\n\n[1] \"90%\"\n\n\n\n\nExtracting movie synopsis\n\nsynopsis <- movie_page %>% \n  html_node(\"#movieSynopsis\") %>% \n  html_text2()\n\nsynopsis\n\n[1] \"In the years before the Civil War, Solomon Northup (Chiwetel Ejiofor), a free black man from upstate New York, is kidnapped and sold into slavery in the South. Subjected to the cruelty of one malevolent owner (Michael Fassbender), he also finds unexpected kindness from another, as he struggles continually to survive and maintain some of his dignity. Then in the 12th year of the disheartening ordeal, a chance meeting with an abolitionist from Canada changes Solomon's life forever.\"\n\n\n\n\nMakinging a data frame of extracted elements\n\nmovie  <- tibble(title = title, \n                 year_genre_runtime = year_genre_runtime,\n                 critics_score = critics_score,\n                 audience_score = audience_score,\n                 synopsis = synopsis,  \n                 url = url)\n\nmovie %>% glimpse()\n\nRows: 1\nColumns: 6\n$ title              <chr> \"12 Years a Slave\"\n$ year_genre_runtime <chr> \"2013, History/Drama, 2h 14m\"\n$ critics_score      <chr> \"95%\"\n$ audience_score     <chr> \"90%\"\n$ synopsis           <chr> \"In the years before the Civil War, Solomon Northup…\n$ url                <chr> \"https://www.rottentomatoes.com/m/12_years_a_slave\""
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#writing-a-function",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#writing-a-function",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "3. Writing a function",
    "text": "3. Writing a function\nInstead of manually scraping individual movies, I’ll write a function to do the same.\n\nscrape_movie <- function(x, ...){\n  \n  movie_page <- read_html(x)\n  \n  title <- movie_page %>% \n    html_node(\".scoreboard__title\") %>% \n    html_text()\n  \n  year_genre_runtime <- movie_page %>% \n    html_node(\".scoreboard__info\") %>% \n    html_text()\n  \n  critics_score <- movie_page %>% \n    html_element(\"score-board\") %>% \n    html_attr(\"tomatometerscore\") %>% \n    str_c(.,\"%\")\n  \n  audience_score <- movie_page %>% \n    html_element(\"score-board\") %>% \n    html_attr(\"audiencescore\") %>% \n    str_c(.,\"%\")\n  \n  synopsis <- movie_page %>% \n    html_node(\"#movieSynopsis\") %>% \n    html_text2()\n  \n  movie_df <- tibble(title = title, \n                     year_genre_runtime = year_genre_runtime,\n                     critics_score = critics_score,\n                     audience_score = audience_score,\n                     synopsis = synopsis,\n                     url = x)\n  \n  return(movie_df)\n  \n}\n\n\nFunction in action\nNow that we have the scrape_movie() function, let’s scrape data for the movie “American Hustle”.\n\nscrape_movie(movie_urls[6]) %>% glimpse()\n\nRows: 1\nColumns: 6\n$ title              <chr> \"American Hustle\"\n$ year_genre_runtime <chr> \"2013, Crime/Drama, 2h 18m\"\n$ critics_score      <chr> \"92%\"\n$ audience_score     <chr> \"74%\"\n$ synopsis           <chr> \"Irving Rosenfeld (Christian Bale) dabbles in forge…\n$ url                <chr> \"https://www.rottentomatoes.com/m/american_hustle\"\n\n\nOr “Ex Machina” (an interesting SF movie).\n\n scrape_movie(movie_urls[53]) %>% glimpse()\n\nRows: 1\nColumns: 6\n$ title              <chr> \"Ex Machina\"\n$ year_genre_runtime <chr> \"2014, Sci-fi/Mystery & thriller, 1h 47m\"\n$ critics_score      <chr> \"92%\"\n$ audience_score     <chr> \"86%\"\n$ synopsis           <chr> \"Caleb Smith (Domhnall Gleeson) a programmer at a h…\n$ url                <chr> \"https://www.rottentomatoes.com/m/ex_machina\""
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#iteration",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#iteration",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "4. Iteration",
    "text": "4. Iteration\nTo make my workflow a little more efficient, I make use of the map_dfr() function from the purrr package to iterate over all movie pages. map_dfr() will apply the scrape_movie()function to each element in the vector of links, and return a data frame created by row-binding. It’s as simple as that.\n\nmovies <- map_dfr(movie_urls, scrape_movie)\n\nmovies \n\n# A tibble: 200 × 6\n   title                year_genre_runtime         criti…¹ audie…² synop…³ url  \n   <chr>                <chr>                      <chr>   <chr>   <chr>   <chr>\n 1 12 Years a Slave     2013, History/Drama, 2h 1… 95%     90%     In the… http…\n 2 20 Feet From Stardom 2013, Documentary, 1h 30m  99%     82%     Filmma… http…\n 3 45 Years             2015, Drama, 1h 33m        97%     67%     As the… http…\n 4 All Is Lost          2013, Adventure/Mystery &… 94%     64%     During… http…\n 5 Amazing Grace        2018, Documentary/Music, … 99%     80%     Singer… http…\n 6 American Hustle      2013, Crime/Drama, 2h 18m  92%     74%     Irving… http…\n 7 Amy                  2015, Documentary/Biograp… 95%     87%     Archiv… http…\n 8 Anomalisa            2015, Comedy/Drama, 1h 30m 91%     71%     An ins… http…\n 9 Ant-Man and The Wasp 2018, Action/Adventure, 1… 87%     80%     Scott … http…\n10 Apollo 11            2019, Documentary/History… 99%     90%     Never-… http…\n# … with 190 more rows, and abbreviated variable names ¹​critics_score,\n#   ²​audience_score, ³​synopsis"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#downloading-images",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#downloading-images",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "5. Downloading images",
    "text": "5. Downloading images\nI’ve already extracted urls of images in the first step and saved them to image_urls. Now I’m going to create a directory and directory paths for the images.\n\nfs::dir_create(\"images/top_200_images/\")\n\npaths <- c(str_c(\"images/top_200_images/\", sprintf(\"%0.3d\", 1:200), \".jpg\"))\n\npaths %>% head()\n\n[1] \"images/top_200_images/001.jpg\" \"images/top_200_images/002.jpg\"\n[3] \"images/top_200_images/003.jpg\" \"images/top_200_images/004.jpg\"\n[5] \"images/top_200_images/005.jpg\" \"images/top_200_images/006.jpg\"\n\n\nSince Tableau sorts images alphabetically (1, 11, 111, 2, 22, …) by default, these leading zeros will help Tableau to correctly match the images with the data so I don’t have to do it manually.\n\nDownloading images\nThis time I’ll use map2() function from the purrr package, It will apply the download.file() function to pairs of elements from two vectors, image_urls and paths.\n\nmap2(image_urls, paths, function(.x, .y) download.file(.x, .y, mode=\"wb\")) \n\nAre the images properly saved? Let’s read in the image for the first movie.\n\nknitr::include_graphics(\"images/top_200_images/001.jpg\")"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#data-wrangling",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#data-wrangling",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "6. Data wrangling",
    "text": "6. Data wrangling\nPreparing the final dataset for Tableau.\n\nmovies <- movies %>% \n  \n  # separate year_genre_runtime column into year, genre, and runtime\n  separate(year_genre_runtime, sep = \", \", into = c(\"year\", \"genre\", \"runtime\")) %>% \n  mutate(year = as.factor(year)) %>% \n  \n  # separate genre column into primary and secondary genre\n  separate(genre, sep = \"/\", into = c(\"genre_1\", \"genre_2\"), remove = FALSE) %>% \n  \n  # create id column with leading zeroes so Tableau can automatically match the images\n  mutate(id = sprintf(\"%0.3d\", 1:200)) %>% \n  select(id, everything())\n\nmovies %>% head()\n\n# A tibble: 6 × 11\n  id    title  year  genre genre_1 genre_2 runtime criti…¹ audie…² synop…³ url  \n  <chr> <chr>  <fct> <chr> <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>\n1 001   12 Ye… 2013  Hist… History Drama   2h 14m  95%     90%     In the… http…\n2 002   20 Fe… 2013  Docu… Docume… <NA>    1h 30m  99%     82%     Filmma… http…\n3 003   45 Ye… 2015  Drama Drama   <NA>    1h 33m  97%     67%     As the… http…\n4 004   All I… 2013  Adve… Advent… Myster… 1h 45m  94%     64%     During… http…\n5 005   Amazi… 2018  Docu… Docume… Music   1h 27m  99%     80%     Singer… http…\n6 006   Ameri… 2013  Crim… Crime   Drama   2h 18m  92%     74%     Irving… http…\n# … with abbreviated variable names ¹​critics_score, ²​audience_score, ³​synopsis\n\n\n\n# number of unique values in genre column\nmovies$genre %>% unique() %>% length()\n\n[1] 59\n\n\n\n# unique values in genre_1\nmovies$genre_1 %>% unique()\n\n [1] \"History\"            \"Documentary\"        \"Drama\"             \n [4] \"Adventure\"          \"Crime\"              \"Comedy\"            \n [7] \"Action\"             \"Sci-fi\"             \"Romance\"           \n[10] \"Horror\"             \"Biography\"          \"Mystery & thriller\"\n[13] \"Kids & family\"      \"War\"                \"Fantasy\"           \n[16] \"Musical\"            \"Western\"           \n\n\n\n# unique values in genre_2\nmovies$genre_2 %>% unique()\n\n [1] \"Drama\"              NA                   \"Mystery & thriller\"\n [4] \"Music\"              \"Biography\"          \"Adventure\"         \n [7] \"History\"            \"Romance\"            \"Comedy\"            \n[10] \"Lgbtq+\"             \"Action\"             \"War\"               \n[13] \"Fantasy\"            \"Sci-fi\"             \"Crime\"             \n[16] \"Musical\"            \"Western\"            \"Anime\"             \n[19] \"Horror\"            \n\n\nFinding values in genre_2, that are not in genre_1. This will help when creating a list parameter for filtering by primary or secondary genre.\n\nsetdiff(movies$genre_2, movies$genre_1)\n\n[1] NA       \"Music\"  \"Lgbtq+\" \"Anime\" \n\n\n\nDT table\nIf you prefer to search a table for data, then this one is for you!\n\nmovies %>% \n  select(1:9) %>% \n  DT::datatable(rownames = FALSE)\n\n\n\n\n\n\n\n\nWriting file\nI choose to save the data in an excel file only because the csv will remove the leading zeros in the id column.\n\nmovies %>% writexl::write_xlsx(\"datasets/top_200_movies_2010s_rotten_tomatoes.xlsx\")"
  },
  {
    "objectID": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#tableau-dashboard",
    "href": "posts/web-scraping-rotten-tomatoes/rotten-tomatoes.html#tableau-dashboard",
    "title": "Scraping 200 Best Movies of 2010s from Rotten Tomatoes",
    "section": "7. Tableau dashboard",
    "text": "7. Tableau dashboard\nThe final dashboard is created in Tableau. It’s actually a jitter plot, which separates overlapping movies with the same critics’ score.\nTo avoid two filters, one for primary and one for secondary genre, a list parameter is created that filters movies by primary or secondary genre, or “All” values.\nFor the best viewing experience, please click on the full screen in the bottom right corner.\nYou can nteract with the embedded dashboard below or go to Tableau Public. Enjoy!"
  }
]